{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Tokenizer 적용\n",
    "- 적용할지 안할지 결정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting texts: 100%|██████████| 1570/1570 [36:54<00:00,  1.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                 image  \\\n",
      "0        0  5eb8d197d228609e.jpg   \n",
      "1        1  716c2fced083a6a6.jpg   \n",
      "2        2  37f9414beea68229.jpg   \n",
      "3        3  c8ef1b2fdb8dbace.jpg   \n",
      "4        4  4606a9ccbc65f3e5.jpg   \n",
      "...    ...                   ...   \n",
      "1565  1565  d9e230e42838eb4f.jpg   \n",
      "1566  1566  713c484c86197d5b.jpg   \n",
      "1567  1567  9dcfef27d51c3e5e.jpg   \n",
      "1568  1568  43965cc70d7d14e0.jpg   \n",
      "1569  1569  b1dad2db5c2de2da.jpg   \n",
      "\n",
      "                                        corrected_texts  \n",
      "0                      ['<extra_id_0>', '<extra_id_0>']  \n",
      "1     ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "2     ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "3     ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "4     ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "...                                                 ...  \n",
      "1565  ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "1566                   ['<extra_id_0>', '<extra_id_0>']  \n",
      "1567  ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "1568  ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "1569  ['<extra_id_0>', '<extra_id_0>', '<extra_id_0>...  \n",
      "\n",
      "[1570 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from transformers import MT5Tokenizer, MT5ForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "\n",
    "# mT5 모델과 토크나이저 불러오기\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# GPU 사용 가능 시 GPU 사용\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 텍스트 교정 함수\n",
    "def correct_text(text):\n",
    "    input_text = \"correct: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\").to(device)\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(\"./image_texts.csv\")\n",
    "\n",
    "# 교정된 텍스트를 저장할 새로운 컬럼 추가\n",
    "df['corrected_texts'] = ''\n",
    "\n",
    "# 텍스트 교정\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Correcting texts\"):\n",
    "    try:\n",
    "        texts = ast.literal_eval(row['texts'])  # 문자열을 리스트로 변환\n",
    "        corrected_texts = [correct_text(text) for text in texts]\n",
    "        df.at[index, 'corrected_texts'] = str(corrected_texts)  # 리스트를 문자열로 저장\n",
    "    except Exception as e:\n",
    "        print(f\"Error correcting text for index {index}: {e}\")\n",
    "\n",
    "# 교정된 텍스트 출력\n",
    "print(df[['id', 'image', 'corrected_texts']])\n",
    "\n",
    "# 교정된 결과를 CSV 파일로 저장\n",
    "df.to_csv(\"corrected_train_texts.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR + Swin T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from timm import create_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "from textblob import TextBlob\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# os.environ['TESSDATA_PREFIX'] = '../'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # CUDA_LAUNCH_BLOCKING 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일에서 텍스트 데이터를 로드하는 함수\n",
    "def load_text_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return {row['image']: ' '.join(eval(row['texts'])) for _, row in df.iterrows()}\n",
    "\n",
    "# 멀티모달 데이터셋 클래스\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, csv_text_data, transform=None, tokenizer=None, max_len=512):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.csv_text_data = csv_text_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, 0]\n",
    "        img_path = f\"{self.image_dir}/{img_name}\"\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('L')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            text = self.csv_text_data.get(img_name, \"\")\n",
    "            \n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'image': image,\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'labels': torch.tensor(self.df.iloc[idx, 1], dtype=torch.long) if 'target' in self.df.columns else torch.tensor(0),\n",
    "                'image_id': img_name,\n",
    "                'extracted_text': text\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {e}\")\n",
    "            # 오류 발생 시 더미 데이터 반환\n",
    "            return {\n",
    "                'image': torch.zeros((1, 224, 224)),\n",
    "                'input_ids': torch.zeros(self.max_len, dtype=torch.long),\n",
    "                'attention_mask': torch.zeros(self.max_len, dtype=torch.long),\n",
    "                'labels': torch.tensor(0, dtype=torch.long),\n",
    "                'image_id': img_name,\n",
    "                'extracted_text': \"\"\n",
    "            }\n",
    "\n",
    "# 멀티모달 모델 클래스\n",
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.swin_b = create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=0, in_chans=1)\n",
    "        self.bert = AutoModel.from_pretrained('klue/bert-base')\n",
    "        \n",
    "        self.image_proj = nn.Linear(self.swin_b.num_features, 512)\n",
    "        self.text_proj = nn.Linear(self.bert.config.hidden_size, 512)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "                        \n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.swin_b = self.swin_b.to(device)\n",
    "        self.bert = self.bert.to(device)\n",
    "        return self\n",
    "        \n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        image_features = self.swin_b(image)\n",
    "        image_features = self.image_proj(image_features)\n",
    "\n",
    "        text_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_output.last_hidden_state[:, 0, :]\n",
    "        text_features = self.text_proj(text_features)\n",
    "        \n",
    "        text_length = attention_mask.sum(dim=1).float() / attention_mask.shape[1]\n",
    "        text_weight = text_length.unsqueeze(1)\n",
    "        \n",
    "        weighted_text_features = text_features * text_weight\n",
    "        \n",
    "        attended_features, _ = self.attention(image_features.unsqueeze(0), \n",
    "                                              weighted_text_features.unsqueeze(0), \n",
    "                                              weighted_text_features.unsqueeze(0))\n",
    "        attended_features = attended_features.squeeze(0)\n",
    "        \n",
    "        combined_features = torch.cat((image_features, attended_features), dim=1)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "        \n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "\n",
    "# 학습 함수\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad(set_to_none=True)  # 메모리 사용량 최적화\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        images = batch['image'].to(device, non_blocking=True)\n",
    "        labels = batch['labels'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            images = batch['image'].to(device, non_blocking=True)\n",
    "            labels = batch['labels'].to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(images, input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    return avg_loss, f1\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.best_f1 = -np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, f1_score, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, f1_score, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, f1_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, f1_score, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). '\n",
    "                            f'F1 score: {f1_score:.6f}. Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "        self.best_f1 = f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.54it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 2.0785\n",
      "Val Loss: 0.9926, Val F1 Score: 0.6583\n",
      "Validation loss decreased (inf --> 0.992551). F1 score: 0.658349. Saving model ...\n",
      "New best F1 score: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "Train Loss: 0.6815\n",
      "Val Loss: 0.3326, Val F1 Score: 0.8652\n",
      "Validation loss decreased (0.992551 --> 0.332634). F1 score: 0.865195. Saving model ...\n",
      "New best F1 score: 0.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "Train Loss: 0.3374\n",
      "Val Loss: 0.2425, Val F1 Score: 0.9067\n",
      "Validation loss decreased (0.332634 --> 0.242477). F1 score: 0.906682. Saving model ...\n",
      "New best F1 score: 0.9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "Train Loss: 0.2082\n",
      "Val Loss: 0.2088, Val F1 Score: 0.9091\n",
      "Validation loss decreased (0.242477 --> 0.208772). F1 score: 0.909058. Saving model ...\n",
      "New best F1 score: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "Train Loss: 0.1403\n",
      "Val Loss: 0.1681, Val F1 Score: 0.9244\n",
      "Validation loss decreased (0.208772 --> 0.168056). F1 score: 0.924386. Saving model ...\n",
      "New best F1 score: 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "Train Loss: 0.0982\n",
      "Val Loss: 0.1830, Val F1 Score: 0.9185\n",
      "EarlyStopping counter: 1 out of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "Train Loss: 0.0708\n",
      "Val Loss: 0.1287, Val F1 Score: 0.9427\n",
      "Validation loss decreased (0.168056 --> 0.128667). F1 score: 0.942688. Saving model ...\n",
      "New best F1 score: 0.9427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "Train Loss: 0.0458\n",
      "Val Loss: 0.1461, Val F1 Score: 0.9408\n",
      "EarlyStopping counter: 1 out of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "Train Loss: 0.0250\n",
      "Val Loss: 0.1553, Val F1 Score: 0.9355\n",
      "EarlyStopping counter: 2 out of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "Train Loss: 0.0182\n",
      "Val Loss: 0.1593, Val F1 Score: 0.9435\n",
      "EarlyStopping counter: 3 out of 7\n",
      "New best F1 score: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "Train Loss: 0.0140\n",
      "Val Loss: 0.1450, Val F1 Score: 0.9450\n",
      "EarlyStopping counter: 4 out of 7\n",
      "New best F1 score: 0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "Train Loss: 0.0114\n",
      "Val Loss: 0.1523, Val F1 Score: 0.9394\n",
      "EarlyStopping counter: 5 out of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "Train Loss: 0.0097\n",
      "Val Loss: 0.1537, Val F1 Score: 0.9568\n",
      "EarlyStopping counter: 6 out of 7\n",
      "New best F1 score: 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "Train Loss: 0.0088\n",
      "Val Loss: 0.1605, Val F1 Score: 0.9351\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping. Best validation loss: 0.128667, Best F1 score: 0.942688\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #torch.multiprocessing.set_start_method('spawn')\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 데이터 경로 설정\n",
    "    data_path = '../data/'\n",
    "    \n",
    "    # PaddleOCR로 추출한 텍스트 데이터 로드\n",
    "    csv_path = './image_texts.csv'\n",
    "    csv_text_data = load_text_from_csv(csv_path)\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(f\"{data_path}/train_correct_labeling.csv\")\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "    test_df = pd.read_csv(f\"{data_path}/sample_submission.csv\")\n",
    "\n",
    "    # 토크나이저 및 변환 준비\n",
    "    tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229])  # 그레이스케일 이미지에 맞는 값 사용\n",
    "    ])\n",
    "\n",
    "    # 데이터셋 및 데이터로더 준비\n",
    "    train_dataset = MultimodalDataset(train_df, f\"{data_path}/train_preprocessed\", csv_text_data, transform, tokenizer)\n",
    "    val_dataset = MultimodalDataset(val_df, f\"{data_path}/train_preprocessed\", csv_text_data, transform, tokenizer)\n",
    "    test_dataset = MultimodalDataset(test_df, f\"{data_path}/test_preprocessed\", csv_text_data, transform, tokenizer)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 준비\n",
    "    num_classes = len(df['target'].unique())\n",
    "    model = MultimodalModel(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "    \n",
    "    # 조기 종료 설정\n",
    "    early_stopping = EarlyStopping(patience=7, verbose=True, delta=0.001, path='best_model.pth')\n",
    "\n",
    "    num_epochs = 50\n",
    "    best_f1 = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_f1 = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step()  # 학습률 조정\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "        # 조기 종료 체크 (validation 에러 기준)\n",
    "        early_stopping(val_loss, val_f1, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping. Best validation loss: {early_stopping.val_loss_min:.6f}, \"\n",
    "                  f\"Best F1 score: {early_stopping.best_f1:.6f}\")\n",
    "            break\n",
    "        \n",
    "        # 최고의 F1 스코어 업데이트 (별도로 추적)\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            print(f\"New best F1 score: {best_f1:.4f}\")\n",
    "\n",
    "    # 모델 저장\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242934/3130122214.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n",
      "100%|██████████| 197/197 [01:48<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed and saved to pred.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PaddleOCR로 추출한 테스트 데이터의 텍스트 데이터 로드\n",
    "csv_path = './test_texts.csv'\n",
    "csv_text_data = load_text_from_csv(csv_path)\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_df = pd.read_csv(f\"{data_path}/sample_submission.csv\")\n",
    "\n",
    "# 토크나이저 및 변환 준비\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # 그레이스케일 이미지에 맞는 값 사용\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 및 데이터로더 준비\n",
    "test_dataset = MultimodalDataset(test_df, f\"{data_path}/test_preprocessed\", csv_text_data, transform, tokenizer)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "\n",
    "# 모델 준비\n",
    "num_classes = len(pd.read_csv(f\"{data_path}/train_correct_labeling.csv\")['target'].unique())\n",
    "model = MultimodalModel(num_classes).to(device)\n",
    "\n",
    "# 저장된 모델 불러오기\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded. Starting test data prediction...\")\n",
    "\n",
    "# 테스트 데이터 추론\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting test data\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        images = batch['image'].to(device)\n",
    "        \n",
    "        outputs = model(images, input_ids, attention_mask)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 결과 저장\n",
    "submission_df = pd.DataFrame({'ID': test_df['ID'], 'target': test_predictions})\n",
    "submission_df.to_csv(\"multimodal_pred.csv\", index=False)\n",
    "print(\"Test predictions saved to multimodal_pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

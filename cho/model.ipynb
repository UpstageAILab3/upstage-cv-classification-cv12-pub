{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 기반 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = '../data/'\n",
    "model_name = 'efficientnet_b0'\n",
    "img_size = 384\n",
    "LR = 1e-3\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 4\n",
    "\n",
    "# 데이터 증강 설정\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 분할\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "train_dataset = ImageDataset(train_df, \"../data/train_preprocessed/\", transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, \"../data/train_preprocessed/\", transform=val_transform)\n",
    "test_dataset = ImageDataset(\"../data/sample_submission.csv\", \"../data/test_preprocessed/\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "    \n",
    "# 모델 구조 출력\n",
    "print(f\"\\nModel structure of {model_name}:\")\n",
    "print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "# 모델 아키텍처 출력\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프\n",
    "best_val_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 추론\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "preds_list = []\n",
    "\n",
    "for image, _ in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(\"pred.csv\", index=False)\n",
    "print(\"Prediction completed and saved to pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet-B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((380, 380, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = 'efficientnet_b4'\n",
    "    img_size = 380  # EfficientNet-B4에 적합한 이미지 크기\n",
    "    LR = 5e-4  # 학습률 조정\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 16  # 배치 크기 감소\n",
    "    num_workers = 4\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "    test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 모델 설정\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 모델 구조 출력\n",
    "    print(f\"\\nModel structure of {model_name}:\")\n",
    "    print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "    # 학습 루프\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    # 테스트 데이터 추론\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "\n",
    "    for image, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "    # 결과 저장\n",
    "    pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "    pred_df['target'] = preds_list\n",
    "    pred_df.to_csv(\"pred.csv\", index=False)\n",
    "    print(\"Prediction completed and saved to pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNext V2 Large 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = 'convnextv2_large'\n",
    "    img_size = 224  # ConvNeXt V2 Large에 적합한 이미지 크기\n",
    "    LR = 1e-4  # 학습률 조정\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 32  # 배치 크기 조정\n",
    "    num_workers = 4\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "    test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 모델 설정\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 모델 구조 출력\n",
    "    print(f\"\\nModel structure of {model_name}:\")\n",
    "    print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "    # 학습 루프\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"convNext_model.pth\")\n",
    "\n",
    "    # 테스트 데이터 추론\n",
    "    model.load_state_dict(torch.load(\"convNext_model.pth\"))\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "\n",
    "    for image, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "    # 결과 저장\n",
    "    pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "    pred_df['target'] = preds_list\n",
    "    pred_df.to_csv(\"pred.csv\", index=False)\n",
    "    print(\"Prediction completed and saved to pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convNext v2 + fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model structure of convnextv2_large:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 192, 56, 56]           9,408\n",
      "       LayerNorm2d-2          [-1, 192, 56, 56]             384\n",
      "          Identity-3          [-1, 192, 56, 56]               0\n",
      "            Conv2d-4          [-1, 192, 56, 56]           9,600\n",
      "         LayerNorm-5          [-1, 56, 56, 192]             384\n",
      "            Linear-6          [-1, 56, 56, 768]         148,224\n",
      "              GELU-7          [-1, 56, 56, 768]               0\n",
      "           Dropout-8          [-1, 56, 56, 768]               0\n",
      "GlobalResponseNorm-9          [-1, 56, 56, 768]           1,536\n",
      "           Linear-10          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-11          [-1, 56, 56, 192]               0\n",
      "GlobalResponseNormMlp-12          [-1, 56, 56, 192]               0\n",
      "         Identity-13          [-1, 192, 56, 56]               0\n",
      "         Identity-14          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtBlock-15          [-1, 192, 56, 56]               0\n",
      "           Conv2d-16          [-1, 192, 56, 56]           9,600\n",
      "        LayerNorm-17          [-1, 56, 56, 192]             384\n",
      "           Linear-18          [-1, 56, 56, 768]         148,224\n",
      "             GELU-19          [-1, 56, 56, 768]               0\n",
      "          Dropout-20          [-1, 56, 56, 768]               0\n",
      "GlobalResponseNorm-21          [-1, 56, 56, 768]           1,536\n",
      "           Linear-22          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-23          [-1, 56, 56, 192]               0\n",
      "GlobalResponseNormMlp-24          [-1, 56, 56, 192]               0\n",
      "         Identity-25          [-1, 192, 56, 56]               0\n",
      "         Identity-26          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtBlock-27          [-1, 192, 56, 56]               0\n",
      "           Conv2d-28          [-1, 192, 56, 56]           9,600\n",
      "        LayerNorm-29          [-1, 56, 56, 192]             384\n",
      "           Linear-30          [-1, 56, 56, 768]         148,224\n",
      "             GELU-31          [-1, 56, 56, 768]               0\n",
      "          Dropout-32          [-1, 56, 56, 768]               0\n",
      "GlobalResponseNorm-33          [-1, 56, 56, 768]           1,536\n",
      "           Linear-34          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-35          [-1, 56, 56, 192]               0\n",
      "GlobalResponseNormMlp-36          [-1, 56, 56, 192]               0\n",
      "         Identity-37          [-1, 192, 56, 56]               0\n",
      "         Identity-38          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtBlock-39          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtStage-40          [-1, 192, 56, 56]               0\n",
      "      LayerNorm2d-41          [-1, 192, 56, 56]             384\n",
      "           Conv2d-42          [-1, 384, 28, 28]         295,296\n",
      "           Conv2d-43          [-1, 384, 28, 28]          19,200\n",
      "        LayerNorm-44          [-1, 28, 28, 384]             768\n",
      "           Linear-45         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-46         [-1, 28, 28, 1536]               0\n",
      "          Dropout-47         [-1, 28, 28, 1536]               0\n",
      "GlobalResponseNorm-48         [-1, 28, 28, 1536]           3,072\n",
      "           Linear-49          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-50          [-1, 28, 28, 384]               0\n",
      "GlobalResponseNormMlp-51          [-1, 28, 28, 384]               0\n",
      "         Identity-52          [-1, 384, 28, 28]               0\n",
      "         Identity-53          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtBlock-54          [-1, 384, 28, 28]               0\n",
      "           Conv2d-55          [-1, 384, 28, 28]          19,200\n",
      "        LayerNorm-56          [-1, 28, 28, 384]             768\n",
      "           Linear-57         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-58         [-1, 28, 28, 1536]               0\n",
      "          Dropout-59         [-1, 28, 28, 1536]               0\n",
      "GlobalResponseNorm-60         [-1, 28, 28, 1536]           3,072\n",
      "           Linear-61          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-62          [-1, 28, 28, 384]               0\n",
      "GlobalResponseNormMlp-63          [-1, 28, 28, 384]               0\n",
      "         Identity-64          [-1, 384, 28, 28]               0\n",
      "         Identity-65          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtBlock-66          [-1, 384, 28, 28]               0\n",
      "           Conv2d-67          [-1, 384, 28, 28]          19,200\n",
      "        LayerNorm-68          [-1, 28, 28, 384]             768\n",
      "           Linear-69         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-70         [-1, 28, 28, 1536]               0\n",
      "          Dropout-71         [-1, 28, 28, 1536]               0\n",
      "GlobalResponseNorm-72         [-1, 28, 28, 1536]           3,072\n",
      "           Linear-73          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-74          [-1, 28, 28, 384]               0\n",
      "GlobalResponseNormMlp-75          [-1, 28, 28, 384]               0\n",
      "         Identity-76          [-1, 384, 28, 28]               0\n",
      "         Identity-77          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtBlock-78          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtStage-79          [-1, 384, 28, 28]               0\n",
      "      LayerNorm2d-80          [-1, 384, 28, 28]             768\n",
      "           Conv2d-81          [-1, 768, 14, 14]       1,180,416\n",
      "           Conv2d-82          [-1, 768, 14, 14]          38,400\n",
      "        LayerNorm-83          [-1, 14, 14, 768]           1,536\n",
      "           Linear-84         [-1, 14, 14, 3072]       2,362,368\n",
      "             GELU-85         [-1, 14, 14, 3072]               0\n",
      "          Dropout-86         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-87         [-1, 14, 14, 3072]           6,144\n",
      "           Linear-88          [-1, 14, 14, 768]       2,360,064\n",
      "          Dropout-89          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-90          [-1, 14, 14, 768]               0\n",
      "         Identity-91          [-1, 768, 14, 14]               0\n",
      "         Identity-92          [-1, 768, 14, 14]               0\n",
      "    ConvNeXtBlock-93          [-1, 768, 14, 14]               0\n",
      "           Conv2d-94          [-1, 768, 14, 14]          38,400\n",
      "        LayerNorm-95          [-1, 14, 14, 768]           1,536\n",
      "           Linear-96         [-1, 14, 14, 3072]       2,362,368\n",
      "             GELU-97         [-1, 14, 14, 3072]               0\n",
      "          Dropout-98         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-99         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-100          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-101          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-102          [-1, 14, 14, 768]               0\n",
      "        Identity-103          [-1, 768, 14, 14]               0\n",
      "        Identity-104          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-105          [-1, 768, 14, 14]               0\n",
      "          Conv2d-106          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-107          [-1, 14, 14, 768]           1,536\n",
      "          Linear-108         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-109         [-1, 14, 14, 3072]               0\n",
      "         Dropout-110         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-111         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-112          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-113          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-114          [-1, 14, 14, 768]               0\n",
      "        Identity-115          [-1, 768, 14, 14]               0\n",
      "        Identity-116          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-117          [-1, 768, 14, 14]               0\n",
      "          Conv2d-118          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-119          [-1, 14, 14, 768]           1,536\n",
      "          Linear-120         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-121         [-1, 14, 14, 3072]               0\n",
      "         Dropout-122         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-123         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-124          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-125          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-126          [-1, 14, 14, 768]               0\n",
      "        Identity-127          [-1, 768, 14, 14]               0\n",
      "        Identity-128          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-129          [-1, 768, 14, 14]               0\n",
      "          Conv2d-130          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-131          [-1, 14, 14, 768]           1,536\n",
      "          Linear-132         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-133         [-1, 14, 14, 3072]               0\n",
      "         Dropout-134         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-135         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-136          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-137          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-138          [-1, 14, 14, 768]               0\n",
      "        Identity-139          [-1, 768, 14, 14]               0\n",
      "        Identity-140          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-141          [-1, 768, 14, 14]               0\n",
      "          Conv2d-142          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-143          [-1, 14, 14, 768]           1,536\n",
      "          Linear-144         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-145         [-1, 14, 14, 3072]               0\n",
      "         Dropout-146         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-147         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-148          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-149          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-150          [-1, 14, 14, 768]               0\n",
      "        Identity-151          [-1, 768, 14, 14]               0\n",
      "        Identity-152          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-153          [-1, 768, 14, 14]               0\n",
      "          Conv2d-154          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-155          [-1, 14, 14, 768]           1,536\n",
      "          Linear-156         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-157         [-1, 14, 14, 3072]               0\n",
      "         Dropout-158         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-159         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-160          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-161          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-162          [-1, 14, 14, 768]               0\n",
      "        Identity-163          [-1, 768, 14, 14]               0\n",
      "        Identity-164          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-165          [-1, 768, 14, 14]               0\n",
      "          Conv2d-166          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-167          [-1, 14, 14, 768]           1,536\n",
      "          Linear-168         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-169         [-1, 14, 14, 3072]               0\n",
      "         Dropout-170         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-171         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-172          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-173          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-174          [-1, 14, 14, 768]               0\n",
      "        Identity-175          [-1, 768, 14, 14]               0\n",
      "        Identity-176          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-177          [-1, 768, 14, 14]               0\n",
      "          Conv2d-178          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-179          [-1, 14, 14, 768]           1,536\n",
      "          Linear-180         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-181         [-1, 14, 14, 3072]               0\n",
      "         Dropout-182         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-183         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-184          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-185          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-186          [-1, 14, 14, 768]               0\n",
      "        Identity-187          [-1, 768, 14, 14]               0\n",
      "        Identity-188          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-189          [-1, 768, 14, 14]               0\n",
      "          Conv2d-190          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-191          [-1, 14, 14, 768]           1,536\n",
      "          Linear-192         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-193         [-1, 14, 14, 3072]               0\n",
      "         Dropout-194         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-195         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-196          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-197          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-198          [-1, 14, 14, 768]               0\n",
      "        Identity-199          [-1, 768, 14, 14]               0\n",
      "        Identity-200          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-201          [-1, 768, 14, 14]               0\n",
      "          Conv2d-202          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-203          [-1, 14, 14, 768]           1,536\n",
      "          Linear-204         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-205         [-1, 14, 14, 3072]               0\n",
      "         Dropout-206         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-207         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-208          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-209          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-210          [-1, 14, 14, 768]               0\n",
      "        Identity-211          [-1, 768, 14, 14]               0\n",
      "        Identity-212          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-213          [-1, 768, 14, 14]               0\n",
      "          Conv2d-214          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-215          [-1, 14, 14, 768]           1,536\n",
      "          Linear-216         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-217         [-1, 14, 14, 3072]               0\n",
      "         Dropout-218         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-219         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-220          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-221          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-222          [-1, 14, 14, 768]               0\n",
      "        Identity-223          [-1, 768, 14, 14]               0\n",
      "        Identity-224          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-225          [-1, 768, 14, 14]               0\n",
      "          Conv2d-226          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-227          [-1, 14, 14, 768]           1,536\n",
      "          Linear-228         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-229         [-1, 14, 14, 3072]               0\n",
      "         Dropout-230         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-231         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-232          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-233          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-234          [-1, 14, 14, 768]               0\n",
      "        Identity-235          [-1, 768, 14, 14]               0\n",
      "        Identity-236          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-237          [-1, 768, 14, 14]               0\n",
      "          Conv2d-238          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-239          [-1, 14, 14, 768]           1,536\n",
      "          Linear-240         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-241         [-1, 14, 14, 3072]               0\n",
      "         Dropout-242         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-243         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-244          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-245          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-246          [-1, 14, 14, 768]               0\n",
      "        Identity-247          [-1, 768, 14, 14]               0\n",
      "        Identity-248          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-249          [-1, 768, 14, 14]               0\n",
      "          Conv2d-250          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-251          [-1, 14, 14, 768]           1,536\n",
      "          Linear-252         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-253         [-1, 14, 14, 3072]               0\n",
      "         Dropout-254         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-255         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-256          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-257          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-258          [-1, 14, 14, 768]               0\n",
      "        Identity-259          [-1, 768, 14, 14]               0\n",
      "        Identity-260          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-261          [-1, 768, 14, 14]               0\n",
      "          Conv2d-262          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-263          [-1, 14, 14, 768]           1,536\n",
      "          Linear-264         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-265         [-1, 14, 14, 3072]               0\n",
      "         Dropout-266         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-267         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-268          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-269          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-270          [-1, 14, 14, 768]               0\n",
      "        Identity-271          [-1, 768, 14, 14]               0\n",
      "        Identity-272          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-273          [-1, 768, 14, 14]               0\n",
      "          Conv2d-274          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-275          [-1, 14, 14, 768]           1,536\n",
      "          Linear-276         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-277         [-1, 14, 14, 3072]               0\n",
      "         Dropout-278         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-279         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-280          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-281          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-282          [-1, 14, 14, 768]               0\n",
      "        Identity-283          [-1, 768, 14, 14]               0\n",
      "        Identity-284          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-285          [-1, 768, 14, 14]               0\n",
      "          Conv2d-286          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-287          [-1, 14, 14, 768]           1,536\n",
      "          Linear-288         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-289         [-1, 14, 14, 3072]               0\n",
      "         Dropout-290         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-291         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-292          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-293          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-294          [-1, 14, 14, 768]               0\n",
      "        Identity-295          [-1, 768, 14, 14]               0\n",
      "        Identity-296          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-297          [-1, 768, 14, 14]               0\n",
      "          Conv2d-298          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-299          [-1, 14, 14, 768]           1,536\n",
      "          Linear-300         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-301         [-1, 14, 14, 3072]               0\n",
      "         Dropout-302         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-303         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-304          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-305          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-306          [-1, 14, 14, 768]               0\n",
      "        Identity-307          [-1, 768, 14, 14]               0\n",
      "        Identity-308          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-309          [-1, 768, 14, 14]               0\n",
      "          Conv2d-310          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-311          [-1, 14, 14, 768]           1,536\n",
      "          Linear-312         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-313         [-1, 14, 14, 3072]               0\n",
      "         Dropout-314         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-315         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-316          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-317          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-318          [-1, 14, 14, 768]               0\n",
      "        Identity-319          [-1, 768, 14, 14]               0\n",
      "        Identity-320          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-321          [-1, 768, 14, 14]               0\n",
      "          Conv2d-322          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-323          [-1, 14, 14, 768]           1,536\n",
      "          Linear-324         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-325         [-1, 14, 14, 3072]               0\n",
      "         Dropout-326         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-327         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-328          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-329          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-330          [-1, 14, 14, 768]               0\n",
      "        Identity-331          [-1, 768, 14, 14]               0\n",
      "        Identity-332          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-333          [-1, 768, 14, 14]               0\n",
      "          Conv2d-334          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-335          [-1, 14, 14, 768]           1,536\n",
      "          Linear-336         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-337         [-1, 14, 14, 3072]               0\n",
      "         Dropout-338         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-339         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-340          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-341          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-342          [-1, 14, 14, 768]               0\n",
      "        Identity-343          [-1, 768, 14, 14]               0\n",
      "        Identity-344          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-345          [-1, 768, 14, 14]               0\n",
      "          Conv2d-346          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-347          [-1, 14, 14, 768]           1,536\n",
      "          Linear-348         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-349         [-1, 14, 14, 3072]               0\n",
      "         Dropout-350         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-351         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-352          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-353          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-354          [-1, 14, 14, 768]               0\n",
      "        Identity-355          [-1, 768, 14, 14]               0\n",
      "        Identity-356          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-357          [-1, 768, 14, 14]               0\n",
      "          Conv2d-358          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-359          [-1, 14, 14, 768]           1,536\n",
      "          Linear-360         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-361         [-1, 14, 14, 3072]               0\n",
      "         Dropout-362         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-363         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-364          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-365          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-366          [-1, 14, 14, 768]               0\n",
      "        Identity-367          [-1, 768, 14, 14]               0\n",
      "        Identity-368          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-369          [-1, 768, 14, 14]               0\n",
      "          Conv2d-370          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-371          [-1, 14, 14, 768]           1,536\n",
      "          Linear-372         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-373         [-1, 14, 14, 3072]               0\n",
      "         Dropout-374         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-375         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-376          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-377          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-378          [-1, 14, 14, 768]               0\n",
      "        Identity-379          [-1, 768, 14, 14]               0\n",
      "        Identity-380          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-381          [-1, 768, 14, 14]               0\n",
      "          Conv2d-382          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-383          [-1, 14, 14, 768]           1,536\n",
      "          Linear-384         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-385         [-1, 14, 14, 3072]               0\n",
      "         Dropout-386         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-387         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-388          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-389          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-390          [-1, 14, 14, 768]               0\n",
      "        Identity-391          [-1, 768, 14, 14]               0\n",
      "        Identity-392          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-393          [-1, 768, 14, 14]               0\n",
      "          Conv2d-394          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-395          [-1, 14, 14, 768]           1,536\n",
      "          Linear-396         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-397         [-1, 14, 14, 3072]               0\n",
      "         Dropout-398         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-399         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-400          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-401          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-402          [-1, 14, 14, 768]               0\n",
      "        Identity-403          [-1, 768, 14, 14]               0\n",
      "        Identity-404          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-405          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtStage-406          [-1, 768, 14, 14]               0\n",
      "     LayerNorm2d-407          [-1, 768, 14, 14]           1,536\n",
      "          Conv2d-408           [-1, 1536, 7, 7]       4,720,128\n",
      "          Conv2d-409           [-1, 1536, 7, 7]          76,800\n",
      "       LayerNorm-410           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-411           [-1, 7, 7, 6144]       9,443,328\n",
      "            GELU-412           [-1, 7, 7, 6144]               0\n",
      "         Dropout-413           [-1, 7, 7, 6144]               0\n",
      "GlobalResponseNorm-414           [-1, 7, 7, 6144]          12,288\n",
      "          Linear-415           [-1, 7, 7, 1536]       9,438,720\n",
      "         Dropout-416           [-1, 7, 7, 1536]               0\n",
      "GlobalResponseNormMlp-417           [-1, 7, 7, 1536]               0\n",
      "        Identity-418           [-1, 1536, 7, 7]               0\n",
      "        Identity-419           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtBlock-420           [-1, 1536, 7, 7]               0\n",
      "          Conv2d-421           [-1, 1536, 7, 7]          76,800\n",
      "       LayerNorm-422           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-423           [-1, 7, 7, 6144]       9,443,328\n",
      "            GELU-424           [-1, 7, 7, 6144]               0\n",
      "         Dropout-425           [-1, 7, 7, 6144]               0\n",
      "GlobalResponseNorm-426           [-1, 7, 7, 6144]          12,288\n",
      "          Linear-427           [-1, 7, 7, 1536]       9,438,720\n",
      "         Dropout-428           [-1, 7, 7, 1536]               0\n",
      "GlobalResponseNormMlp-429           [-1, 7, 7, 1536]               0\n",
      "        Identity-430           [-1, 1536, 7, 7]               0\n",
      "        Identity-431           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtBlock-432           [-1, 1536, 7, 7]               0\n",
      "          Conv2d-433           [-1, 1536, 7, 7]          76,800\n",
      "       LayerNorm-434           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-435           [-1, 7, 7, 6144]       9,443,328\n",
      "            GELU-436           [-1, 7, 7, 6144]               0\n",
      "         Dropout-437           [-1, 7, 7, 6144]               0\n",
      "GlobalResponseNorm-438           [-1, 7, 7, 6144]          12,288\n",
      "          Linear-439           [-1, 7, 7, 1536]       9,438,720\n",
      "         Dropout-440           [-1, 7, 7, 1536]               0\n",
      "GlobalResponseNormMlp-441           [-1, 7, 7, 1536]               0\n",
      "        Identity-442           [-1, 1536, 7, 7]               0\n",
      "        Identity-443           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtBlock-444           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtStage-445           [-1, 1536, 7, 7]               0\n",
      "        Identity-446           [-1, 1536, 7, 7]               0\n",
      "AdaptiveAvgPool2d-447           [-1, 1536, 1, 1]               0\n",
      "        Identity-448           [-1, 1536, 1, 1]               0\n",
      "SelectAdaptivePool2d-449           [-1, 1536, 1, 1]               0\n",
      "     LayerNorm2d-450           [-1, 1536, 1, 1]           3,072\n",
      "         Flatten-451                 [-1, 1536]               0\n",
      "        Identity-452                 [-1, 1536]               0\n",
      "         Dropout-453                 [-1, 1536]               0\n",
      "          Linear-454                   [-1, 17]          26,129\n",
      "NormMlpClassifierHead-455                   [-1, 17]               0\n",
      "================================================================\n",
      "Total params: 196,445,969\n",
      "Trainable params: 196,445,969\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1316.77\n",
      "Params size (MB): 749.38\n",
      "Estimated Total Size (MB): 2066.72\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2666: 100%|██████████| 40/40 [00:29<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.9142, Train Acc: 0.7142, Train F1: 0.6951\n",
      "Val Loss: 0.3429, Val Acc: 0.8758, Val F1: 0.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0162: 100%|██████████| 40/40 [00:29<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.2789, Train Acc: 0.8941, Train F1: 0.8816\n",
      "Val Loss: 0.3312, Val Acc: 0.8662, Val F1: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0052: 100%|██████████| 40/40 [00:29<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.2074, Train Acc: 0.9188, Train F1: 0.9083\n",
      "Val Loss: 0.2308, Val Acc: 0.9204, Val F1: 0.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5555: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.1710, Train Acc: 0.9347, Train F1: 0.9280\n",
      "Val Loss: 0.2320, Val Acc: 0.9140, Val F1: 0.9007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2525: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.1384, Train Acc: 0.9443, Train F1: 0.9392\n",
      "Val Loss: 0.1470, Val Acc: 0.9459, Val F1: 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0816: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.0985, Train Acc: 0.9642, Train F1: 0.9626\n",
      "Val Loss: 0.2139, Val Acc: 0.9268, Val F1: 0.9174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0811: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.0926, Train Acc: 0.9697, Train F1: 0.9683\n",
      "Val Loss: 0.2329, Val Acc: 0.8981, Val F1: 0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2371: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.0625, Train Acc: 0.9809, Train F1: 0.9812\n",
      "Val Loss: 0.1600, Val Acc: 0.9459, Val F1: 0.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0015: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0628, Train Acc: 0.9793, Train F1: 0.9774\n",
      "Val Loss: 0.2908, Val Acc: 0.9045, Val F1: 0.8956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0145: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss: 0.0458, Train Acc: 0.9785, Train F1: 0.9777\n",
      "Val Loss: 0.2150, Val Acc: 0.9395, Val F1: 0.9314\n",
      "Early stopping triggered\n",
      "\n",
      "Fine-tuning with misclassified data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2694: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1/5\n",
      "Train Loss: 2.2694, Train Acc: 0.2632, Train F1: 0.1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2706: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 2/5\n",
      "Train Loss: 2.2706, Train Acc: 0.4211, Train F1: 0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8660: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 3/5\n",
      "Train Loss: 0.8660, Train Acc: 0.7368, Train F1: 0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3658: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 4/5\n",
      "Train Loss: 0.3658, Train Acc: 0.8947, Train F1: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3274: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 5/5\n",
      "Train Loss: 0.3274, Train Acc: 0.8947, Train F1: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3086: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 6/5\n",
      "Train Loss: 0.3086, Train Acc: 0.8947, Train F1: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1315: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 7/5\n",
      "Train Loss: 0.1315, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2255: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 8/5\n",
      "Train Loss: 0.2255, Train Acc: 0.9474, Train F1: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1177: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 9/5\n",
      "Train Loss: 0.1177, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1283: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 10/5\n",
      "Train Loss: 0.1283, Train Acc: 0.9474, Train F1: 0.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160351/3141216663.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"convNext_model_final.pth\"))\n",
      "100%|██████████| 99/99 [00:18<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed and saved to pred.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    misclassified = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, targets) in enumerate(loader):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_np = preds.argmax(dim=1).detach().cpu().numpy()\n",
    "            targets_np = targets.detach().cpu().numpy()\n",
    "            preds_list.extend(preds_np)\n",
    "            targets_list.extend(targets_np)\n",
    "\n",
    "            # 오분류된 데이터의 인덱스 저장\n",
    "            misclassified.extend(np.where(preds_np != targets_np)[0] + i * loader.batch_size)\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1, misclassified\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "# EarlyStopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = 'convnextv2_large'\n",
    "    img_size = 224\n",
    "    LR = 1e-4\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 32\n",
    "    num_workers = 4\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train/\"), transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train/\"), transform=val_transform)\n",
    "    test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test/\"), transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 모델 설정\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 모델 구조 출력\n",
    "    print(f\"\\nModel structure of {model_name}:\")\n",
    "    print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "    # EarlyStopping 초기화\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "    # 학습 루프\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc, val_f1, misclassified = validate(val_loader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"convNext_model.pth\")\n",
    "\n",
    "        # Early Stopping 체크\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # 오분류된 데이터로 fine-tuning\n",
    "    misclassified_df = val_df.iloc[misclassified]\n",
    "    misclassified_dataset = ImageDataset(misclassified_df, os.path.join(data_path, \"train/\"), transform=train_transform)\n",
    "    misclassified_loader = DataLoader(misclassified_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    print(\"\\nFine-tuning with misclassified data\")\n",
    "    for epoch in range(10):  # 10 에폭 동안 fine-tuning\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(misclassified_loader, model, optimizer, loss_fn, device)\n",
    "        print(f\"Fine-tuning Epoch {epoch+1}/5\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    torch.save(model.state_dict(), \"convNext_model_final.pth\")\n",
    "\n",
    "    # 테스트 데이터 추론\n",
    "    model.load_state_dict(torch.load(\"convNext_model_final.pth\"))\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "\n",
    "    for image, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "    # 결과 저장\n",
    "    pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "    pred_df['target'] = preds_list\n",
    "    pred_df.to_csv(\"conv_fine_pred.csv\", index=False)\n",
    "    print(\"Prediction completed and saved to pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convNext v2 + new augmentaion + K-Fold finetunning + ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "\n",
      "Model structure of convnextv2_large:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 192, 56, 56]           9,408\n",
      "       LayerNorm2d-2          [-1, 192, 56, 56]             384\n",
      "          Identity-3          [-1, 192, 56, 56]               0\n",
      "            Conv2d-4          [-1, 192, 56, 56]           9,600\n",
      "         LayerNorm-5          [-1, 56, 56, 192]             384\n",
      "            Linear-6          [-1, 56, 56, 768]         148,224\n",
      "              GELU-7          [-1, 56, 56, 768]               0\n",
      "           Dropout-8          [-1, 56, 56, 768]               0\n",
      "GlobalResponseNorm-9          [-1, 56, 56, 768]           1,536\n",
      "           Linear-10          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-11          [-1, 56, 56, 192]               0\n",
      "GlobalResponseNormMlp-12          [-1, 56, 56, 192]               0\n",
      "         Identity-13          [-1, 192, 56, 56]               0\n",
      "         Identity-14          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtBlock-15          [-1, 192, 56, 56]               0\n",
      "           Conv2d-16          [-1, 192, 56, 56]           9,600\n",
      "        LayerNorm-17          [-1, 56, 56, 192]             384\n",
      "           Linear-18          [-1, 56, 56, 768]         148,224\n",
      "             GELU-19          [-1, 56, 56, 768]               0\n",
      "          Dropout-20          [-1, 56, 56, 768]               0\n",
      "GlobalResponseNorm-21          [-1, 56, 56, 768]           1,536\n",
      "           Linear-22          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-23          [-1, 56, 56, 192]               0\n",
      "GlobalResponseNormMlp-24          [-1, 56, 56, 192]               0\n",
      "         Identity-25          [-1, 192, 56, 56]               0\n",
      "         Identity-26          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtBlock-27          [-1, 192, 56, 56]               0\n",
      "           Conv2d-28          [-1, 192, 56, 56]           9,600\n",
      "        LayerNorm-29          [-1, 56, 56, 192]             384\n",
      "           Linear-30          [-1, 56, 56, 768]         148,224\n",
      "             GELU-31          [-1, 56, 56, 768]               0\n",
      "          Dropout-32          [-1, 56, 56, 768]               0\n",
      "GlobalResponseNorm-33          [-1, 56, 56, 768]           1,536\n",
      "           Linear-34          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-35          [-1, 56, 56, 192]               0\n",
      "GlobalResponseNormMlp-36          [-1, 56, 56, 192]               0\n",
      "         Identity-37          [-1, 192, 56, 56]               0\n",
      "         Identity-38          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtBlock-39          [-1, 192, 56, 56]               0\n",
      "    ConvNeXtStage-40          [-1, 192, 56, 56]               0\n",
      "      LayerNorm2d-41          [-1, 192, 56, 56]             384\n",
      "           Conv2d-42          [-1, 384, 28, 28]         295,296\n",
      "           Conv2d-43          [-1, 384, 28, 28]          19,200\n",
      "        LayerNorm-44          [-1, 28, 28, 384]             768\n",
      "           Linear-45         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-46         [-1, 28, 28, 1536]               0\n",
      "          Dropout-47         [-1, 28, 28, 1536]               0\n",
      "GlobalResponseNorm-48         [-1, 28, 28, 1536]           3,072\n",
      "           Linear-49          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-50          [-1, 28, 28, 384]               0\n",
      "GlobalResponseNormMlp-51          [-1, 28, 28, 384]               0\n",
      "         Identity-52          [-1, 384, 28, 28]               0\n",
      "         Identity-53          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtBlock-54          [-1, 384, 28, 28]               0\n",
      "           Conv2d-55          [-1, 384, 28, 28]          19,200\n",
      "        LayerNorm-56          [-1, 28, 28, 384]             768\n",
      "           Linear-57         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-58         [-1, 28, 28, 1536]               0\n",
      "          Dropout-59         [-1, 28, 28, 1536]               0\n",
      "GlobalResponseNorm-60         [-1, 28, 28, 1536]           3,072\n",
      "           Linear-61          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-62          [-1, 28, 28, 384]               0\n",
      "GlobalResponseNormMlp-63          [-1, 28, 28, 384]               0\n",
      "         Identity-64          [-1, 384, 28, 28]               0\n",
      "         Identity-65          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtBlock-66          [-1, 384, 28, 28]               0\n",
      "           Conv2d-67          [-1, 384, 28, 28]          19,200\n",
      "        LayerNorm-68          [-1, 28, 28, 384]             768\n",
      "           Linear-69         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-70         [-1, 28, 28, 1536]               0\n",
      "          Dropout-71         [-1, 28, 28, 1536]               0\n",
      "GlobalResponseNorm-72         [-1, 28, 28, 1536]           3,072\n",
      "           Linear-73          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-74          [-1, 28, 28, 384]               0\n",
      "GlobalResponseNormMlp-75          [-1, 28, 28, 384]               0\n",
      "         Identity-76          [-1, 384, 28, 28]               0\n",
      "         Identity-77          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtBlock-78          [-1, 384, 28, 28]               0\n",
      "    ConvNeXtStage-79          [-1, 384, 28, 28]               0\n",
      "      LayerNorm2d-80          [-1, 384, 28, 28]             768\n",
      "           Conv2d-81          [-1, 768, 14, 14]       1,180,416\n",
      "           Conv2d-82          [-1, 768, 14, 14]          38,400\n",
      "        LayerNorm-83          [-1, 14, 14, 768]           1,536\n",
      "           Linear-84         [-1, 14, 14, 3072]       2,362,368\n",
      "             GELU-85         [-1, 14, 14, 3072]               0\n",
      "          Dropout-86         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-87         [-1, 14, 14, 3072]           6,144\n",
      "           Linear-88          [-1, 14, 14, 768]       2,360,064\n",
      "          Dropout-89          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-90          [-1, 14, 14, 768]               0\n",
      "         Identity-91          [-1, 768, 14, 14]               0\n",
      "         Identity-92          [-1, 768, 14, 14]               0\n",
      "    ConvNeXtBlock-93          [-1, 768, 14, 14]               0\n",
      "           Conv2d-94          [-1, 768, 14, 14]          38,400\n",
      "        LayerNorm-95          [-1, 14, 14, 768]           1,536\n",
      "           Linear-96         [-1, 14, 14, 3072]       2,362,368\n",
      "             GELU-97         [-1, 14, 14, 3072]               0\n",
      "          Dropout-98         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-99         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-100          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-101          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-102          [-1, 14, 14, 768]               0\n",
      "        Identity-103          [-1, 768, 14, 14]               0\n",
      "        Identity-104          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-105          [-1, 768, 14, 14]               0\n",
      "          Conv2d-106          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-107          [-1, 14, 14, 768]           1,536\n",
      "          Linear-108         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-109         [-1, 14, 14, 3072]               0\n",
      "         Dropout-110         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-111         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-112          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-113          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-114          [-1, 14, 14, 768]               0\n",
      "        Identity-115          [-1, 768, 14, 14]               0\n",
      "        Identity-116          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-117          [-1, 768, 14, 14]               0\n",
      "          Conv2d-118          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-119          [-1, 14, 14, 768]           1,536\n",
      "          Linear-120         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-121         [-1, 14, 14, 3072]               0\n",
      "         Dropout-122         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-123         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-124          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-125          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-126          [-1, 14, 14, 768]               0\n",
      "        Identity-127          [-1, 768, 14, 14]               0\n",
      "        Identity-128          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-129          [-1, 768, 14, 14]               0\n",
      "          Conv2d-130          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-131          [-1, 14, 14, 768]           1,536\n",
      "          Linear-132         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-133         [-1, 14, 14, 3072]               0\n",
      "         Dropout-134         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-135         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-136          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-137          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-138          [-1, 14, 14, 768]               0\n",
      "        Identity-139          [-1, 768, 14, 14]               0\n",
      "        Identity-140          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-141          [-1, 768, 14, 14]               0\n",
      "          Conv2d-142          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-143          [-1, 14, 14, 768]           1,536\n",
      "          Linear-144         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-145         [-1, 14, 14, 3072]               0\n",
      "         Dropout-146         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-147         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-148          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-149          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-150          [-1, 14, 14, 768]               0\n",
      "        Identity-151          [-1, 768, 14, 14]               0\n",
      "        Identity-152          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-153          [-1, 768, 14, 14]               0\n",
      "          Conv2d-154          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-155          [-1, 14, 14, 768]           1,536\n",
      "          Linear-156         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-157         [-1, 14, 14, 3072]               0\n",
      "         Dropout-158         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-159         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-160          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-161          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-162          [-1, 14, 14, 768]               0\n",
      "        Identity-163          [-1, 768, 14, 14]               0\n",
      "        Identity-164          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-165          [-1, 768, 14, 14]               0\n",
      "          Conv2d-166          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-167          [-1, 14, 14, 768]           1,536\n",
      "          Linear-168         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-169         [-1, 14, 14, 3072]               0\n",
      "         Dropout-170         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-171         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-172          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-173          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-174          [-1, 14, 14, 768]               0\n",
      "        Identity-175          [-1, 768, 14, 14]               0\n",
      "        Identity-176          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-177          [-1, 768, 14, 14]               0\n",
      "          Conv2d-178          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-179          [-1, 14, 14, 768]           1,536\n",
      "          Linear-180         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-181         [-1, 14, 14, 3072]               0\n",
      "         Dropout-182         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-183         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-184          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-185          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-186          [-1, 14, 14, 768]               0\n",
      "        Identity-187          [-1, 768, 14, 14]               0\n",
      "        Identity-188          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-189          [-1, 768, 14, 14]               0\n",
      "          Conv2d-190          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-191          [-1, 14, 14, 768]           1,536\n",
      "          Linear-192         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-193         [-1, 14, 14, 3072]               0\n",
      "         Dropout-194         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-195         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-196          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-197          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-198          [-1, 14, 14, 768]               0\n",
      "        Identity-199          [-1, 768, 14, 14]               0\n",
      "        Identity-200          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-201          [-1, 768, 14, 14]               0\n",
      "          Conv2d-202          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-203          [-1, 14, 14, 768]           1,536\n",
      "          Linear-204         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-205         [-1, 14, 14, 3072]               0\n",
      "         Dropout-206         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-207         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-208          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-209          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-210          [-1, 14, 14, 768]               0\n",
      "        Identity-211          [-1, 768, 14, 14]               0\n",
      "        Identity-212          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-213          [-1, 768, 14, 14]               0\n",
      "          Conv2d-214          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-215          [-1, 14, 14, 768]           1,536\n",
      "          Linear-216         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-217         [-1, 14, 14, 3072]               0\n",
      "         Dropout-218         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-219         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-220          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-221          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-222          [-1, 14, 14, 768]               0\n",
      "        Identity-223          [-1, 768, 14, 14]               0\n",
      "        Identity-224          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-225          [-1, 768, 14, 14]               0\n",
      "          Conv2d-226          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-227          [-1, 14, 14, 768]           1,536\n",
      "          Linear-228         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-229         [-1, 14, 14, 3072]               0\n",
      "         Dropout-230         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-231         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-232          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-233          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-234          [-1, 14, 14, 768]               0\n",
      "        Identity-235          [-1, 768, 14, 14]               0\n",
      "        Identity-236          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-237          [-1, 768, 14, 14]               0\n",
      "          Conv2d-238          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-239          [-1, 14, 14, 768]           1,536\n",
      "          Linear-240         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-241         [-1, 14, 14, 3072]               0\n",
      "         Dropout-242         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-243         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-244          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-245          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-246          [-1, 14, 14, 768]               0\n",
      "        Identity-247          [-1, 768, 14, 14]               0\n",
      "        Identity-248          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-249          [-1, 768, 14, 14]               0\n",
      "          Conv2d-250          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-251          [-1, 14, 14, 768]           1,536\n",
      "          Linear-252         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-253         [-1, 14, 14, 3072]               0\n",
      "         Dropout-254         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-255         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-256          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-257          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-258          [-1, 14, 14, 768]               0\n",
      "        Identity-259          [-1, 768, 14, 14]               0\n",
      "        Identity-260          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-261          [-1, 768, 14, 14]               0\n",
      "          Conv2d-262          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-263          [-1, 14, 14, 768]           1,536\n",
      "          Linear-264         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-265         [-1, 14, 14, 3072]               0\n",
      "         Dropout-266         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-267         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-268          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-269          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-270          [-1, 14, 14, 768]               0\n",
      "        Identity-271          [-1, 768, 14, 14]               0\n",
      "        Identity-272          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-273          [-1, 768, 14, 14]               0\n",
      "          Conv2d-274          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-275          [-1, 14, 14, 768]           1,536\n",
      "          Linear-276         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-277         [-1, 14, 14, 3072]               0\n",
      "         Dropout-278         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-279         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-280          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-281          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-282          [-1, 14, 14, 768]               0\n",
      "        Identity-283          [-1, 768, 14, 14]               0\n",
      "        Identity-284          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-285          [-1, 768, 14, 14]               0\n",
      "          Conv2d-286          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-287          [-1, 14, 14, 768]           1,536\n",
      "          Linear-288         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-289         [-1, 14, 14, 3072]               0\n",
      "         Dropout-290         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-291         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-292          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-293          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-294          [-1, 14, 14, 768]               0\n",
      "        Identity-295          [-1, 768, 14, 14]               0\n",
      "        Identity-296          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-297          [-1, 768, 14, 14]               0\n",
      "          Conv2d-298          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-299          [-1, 14, 14, 768]           1,536\n",
      "          Linear-300         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-301         [-1, 14, 14, 3072]               0\n",
      "         Dropout-302         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-303         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-304          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-305          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-306          [-1, 14, 14, 768]               0\n",
      "        Identity-307          [-1, 768, 14, 14]               0\n",
      "        Identity-308          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-309          [-1, 768, 14, 14]               0\n",
      "          Conv2d-310          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-311          [-1, 14, 14, 768]           1,536\n",
      "          Linear-312         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-313         [-1, 14, 14, 3072]               0\n",
      "         Dropout-314         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-315         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-316          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-317          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-318          [-1, 14, 14, 768]               0\n",
      "        Identity-319          [-1, 768, 14, 14]               0\n",
      "        Identity-320          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-321          [-1, 768, 14, 14]               0\n",
      "          Conv2d-322          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-323          [-1, 14, 14, 768]           1,536\n",
      "          Linear-324         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-325         [-1, 14, 14, 3072]               0\n",
      "         Dropout-326         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-327         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-328          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-329          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-330          [-1, 14, 14, 768]               0\n",
      "        Identity-331          [-1, 768, 14, 14]               0\n",
      "        Identity-332          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-333          [-1, 768, 14, 14]               0\n",
      "          Conv2d-334          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-335          [-1, 14, 14, 768]           1,536\n",
      "          Linear-336         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-337         [-1, 14, 14, 3072]               0\n",
      "         Dropout-338         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-339         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-340          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-341          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-342          [-1, 14, 14, 768]               0\n",
      "        Identity-343          [-1, 768, 14, 14]               0\n",
      "        Identity-344          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-345          [-1, 768, 14, 14]               0\n",
      "          Conv2d-346          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-347          [-1, 14, 14, 768]           1,536\n",
      "          Linear-348         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-349         [-1, 14, 14, 3072]               0\n",
      "         Dropout-350         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-351         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-352          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-353          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-354          [-1, 14, 14, 768]               0\n",
      "        Identity-355          [-1, 768, 14, 14]               0\n",
      "        Identity-356          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-357          [-1, 768, 14, 14]               0\n",
      "          Conv2d-358          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-359          [-1, 14, 14, 768]           1,536\n",
      "          Linear-360         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-361         [-1, 14, 14, 3072]               0\n",
      "         Dropout-362         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-363         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-364          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-365          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-366          [-1, 14, 14, 768]               0\n",
      "        Identity-367          [-1, 768, 14, 14]               0\n",
      "        Identity-368          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-369          [-1, 768, 14, 14]               0\n",
      "          Conv2d-370          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-371          [-1, 14, 14, 768]           1,536\n",
      "          Linear-372         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-373         [-1, 14, 14, 3072]               0\n",
      "         Dropout-374         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-375         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-376          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-377          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-378          [-1, 14, 14, 768]               0\n",
      "        Identity-379          [-1, 768, 14, 14]               0\n",
      "        Identity-380          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-381          [-1, 768, 14, 14]               0\n",
      "          Conv2d-382          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-383          [-1, 14, 14, 768]           1,536\n",
      "          Linear-384         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-385         [-1, 14, 14, 3072]               0\n",
      "         Dropout-386         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-387         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-388          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-389          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-390          [-1, 14, 14, 768]               0\n",
      "        Identity-391          [-1, 768, 14, 14]               0\n",
      "        Identity-392          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-393          [-1, 768, 14, 14]               0\n",
      "          Conv2d-394          [-1, 768, 14, 14]          38,400\n",
      "       LayerNorm-395          [-1, 14, 14, 768]           1,536\n",
      "          Linear-396         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-397         [-1, 14, 14, 3072]               0\n",
      "         Dropout-398         [-1, 14, 14, 3072]               0\n",
      "GlobalResponseNorm-399         [-1, 14, 14, 3072]           6,144\n",
      "          Linear-400          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-401          [-1, 14, 14, 768]               0\n",
      "GlobalResponseNormMlp-402          [-1, 14, 14, 768]               0\n",
      "        Identity-403          [-1, 768, 14, 14]               0\n",
      "        Identity-404          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtBlock-405          [-1, 768, 14, 14]               0\n",
      "   ConvNeXtStage-406          [-1, 768, 14, 14]               0\n",
      "     LayerNorm2d-407          [-1, 768, 14, 14]           1,536\n",
      "          Conv2d-408           [-1, 1536, 7, 7]       4,720,128\n",
      "          Conv2d-409           [-1, 1536, 7, 7]          76,800\n",
      "       LayerNorm-410           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-411           [-1, 7, 7, 6144]       9,443,328\n",
      "            GELU-412           [-1, 7, 7, 6144]               0\n",
      "         Dropout-413           [-1, 7, 7, 6144]               0\n",
      "GlobalResponseNorm-414           [-1, 7, 7, 6144]          12,288\n",
      "          Linear-415           [-1, 7, 7, 1536]       9,438,720\n",
      "         Dropout-416           [-1, 7, 7, 1536]               0\n",
      "GlobalResponseNormMlp-417           [-1, 7, 7, 1536]               0\n",
      "        Identity-418           [-1, 1536, 7, 7]               0\n",
      "        Identity-419           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtBlock-420           [-1, 1536, 7, 7]               0\n",
      "          Conv2d-421           [-1, 1536, 7, 7]          76,800\n",
      "       LayerNorm-422           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-423           [-1, 7, 7, 6144]       9,443,328\n",
      "            GELU-424           [-1, 7, 7, 6144]               0\n",
      "         Dropout-425           [-1, 7, 7, 6144]               0\n",
      "GlobalResponseNorm-426           [-1, 7, 7, 6144]          12,288\n",
      "          Linear-427           [-1, 7, 7, 1536]       9,438,720\n",
      "         Dropout-428           [-1, 7, 7, 1536]               0\n",
      "GlobalResponseNormMlp-429           [-1, 7, 7, 1536]               0\n",
      "        Identity-430           [-1, 1536, 7, 7]               0\n",
      "        Identity-431           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtBlock-432           [-1, 1536, 7, 7]               0\n",
      "          Conv2d-433           [-1, 1536, 7, 7]          76,800\n",
      "       LayerNorm-434           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-435           [-1, 7, 7, 6144]       9,443,328\n",
      "            GELU-436           [-1, 7, 7, 6144]               0\n",
      "         Dropout-437           [-1, 7, 7, 6144]               0\n",
      "GlobalResponseNorm-438           [-1, 7, 7, 6144]          12,288\n",
      "          Linear-439           [-1, 7, 7, 1536]       9,438,720\n",
      "         Dropout-440           [-1, 7, 7, 1536]               0\n",
      "GlobalResponseNormMlp-441           [-1, 7, 7, 1536]               0\n",
      "        Identity-442           [-1, 1536, 7, 7]               0\n",
      "        Identity-443           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtBlock-444           [-1, 1536, 7, 7]               0\n",
      "   ConvNeXtStage-445           [-1, 1536, 7, 7]               0\n",
      "        Identity-446           [-1, 1536, 7, 7]               0\n",
      "AdaptiveAvgPool2d-447           [-1, 1536, 1, 1]               0\n",
      "        Identity-448           [-1, 1536, 1, 1]               0\n",
      "SelectAdaptivePool2d-449           [-1, 1536, 1, 1]               0\n",
      "     LayerNorm2d-450           [-1, 1536, 1, 1]           3,072\n",
      "         Flatten-451                 [-1, 1536]               0\n",
      "        Identity-452                 [-1, 1536]               0\n",
      "         Dropout-453                 [-1, 1536]               0\n",
      "          Linear-454                   [-1, 17]          26,129\n",
      "NormMlpClassifierHead-455                   [-1, 17]               0\n",
      "================================================================\n",
      "Total params: 196,445,969\n",
      "Trainable params: 196,445,969\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1316.77\n",
      "Params size (MB): 749.38\n",
      "Estimated Total Size (MB): 2066.72\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3000: 100%|██████████| 40/40 [00:29<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.8191, Train Acc: 0.7524, Train F1: 0.7394\n",
      "Val Loss: 0.3038, Val Acc: 0.8790, Val F1: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0397: 100%|██████████| 40/40 [00:29<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.2373, Train Acc: 0.9053, Train F1: 0.8968\n",
      "Val Loss: 0.2177, Val Acc: 0.9045, Val F1: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0291: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.1529, Train Acc: 0.9395, Train F1: 0.9360\n",
      "Val Loss: 0.1973, Val Acc: 0.9108, Val F1: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0148: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.0879, Train Acc: 0.9674, Train F1: 0.9661\n",
      "Val Loss: 0.1966, Val Acc: 0.9331, Val F1: 0.9209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.0640, Train Acc: 0.9777, Train F1: 0.9784\n",
      "Val Loss: 0.1732, Val Acc: 0.9490, Val F1: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.0454, Train Acc: 0.9841, Train F1: 0.9843\n",
      "Val Loss: 0.1889, Val Acc: 0.9522, Val F1: 0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0022: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.0230, Train Acc: 0.9928, Train F1: 0.9934\n",
      "Val Loss: 0.2811, Val Acc: 0.9363, Val F1: 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0028: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.0569, Train Acc: 0.9801, Train F1: 0.9795\n",
      "Val Loss: 0.3390, Val Acc: 0.9045, Val F1: 0.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0018: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0415, Train Acc: 0.9833, Train F1: 0.9827\n",
      "Val Loss: 0.2686, Val Acc: 0.9299, Val F1: 0.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss: 0.0239, Train Acc: 0.9904, Train F1: 0.9909\n",
      "Val Loss: 0.2953, Val Acc: 0.9140, Val F1: 0.9039\n",
      "Early stopping\n",
      "\n",
      "Fine-tuning with misclassified data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.0044, Train Acc: 0.9960, Train F1: 0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Train Loss: 0.0010, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Train Loss: 0.0009, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Train Loss: 0.0003, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Train Loss: 0.0004, Train Acc: 1.0000, Train F1: 1.0000\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2489: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.9736, Train Acc: 0.6990, Train F1: 0.6796\n",
      "Val Loss: 0.4136, Val Acc: 0.8503, Val F1: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0315: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.2272, Train Acc: 0.9156, Train F1: 0.9069\n",
      "Val Loss: 0.1553, Val Acc: 0.9268, Val F1: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0192: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.1267, Train Acc: 0.9498, Train F1: 0.9486\n",
      "Val Loss: 0.2288, Val Acc: 0.9140, Val F1: 0.9112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0719: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.1010, Train Acc: 0.9602, Train F1: 0.9585\n",
      "Val Loss: 0.1379, Val Acc: 0.9459, Val F1: 0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0226: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.0870, Train Acc: 0.9650, Train F1: 0.9625\n",
      "Val Loss: 0.1803, Val Acc: 0.9395, Val F1: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1696: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.0623, Train Acc: 0.9745, Train F1: 0.9749\n",
      "Val Loss: 0.1711, Val Acc: 0.9268, Val F1: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2599: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.0503, Train Acc: 0.9785, Train F1: 0.9782\n",
      "Val Loss: 0.1470, Val Acc: 0.9363, Val F1: 0.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0261: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.0366, Train Acc: 0.9881, Train F1: 0.9881\n",
      "Val Loss: 0.1707, Val Acc: 0.9459, Val F1: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0233, Train Acc: 0.9896, Train F1: 0.9893\n",
      "Val Loss: 0.2952, Val Acc: 0.9140, Val F1: 0.9135\n",
      "Early stopping\n",
      "\n",
      "Fine-tuning with misclassified data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0355: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.0431, Train Acc: 0.9773, Train F1: 0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0015: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Train Loss: 0.0030, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0031: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Train Loss: 0.0017, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0005: 100%|██████████| 7/7 [00:05<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Train Loss: 0.0009, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Train Loss: 0.0004, Train Acc: 1.0000, Train F1: 1.0000\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3387: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.8628, Train Acc: 0.7357, Train F1: 0.7151\n",
      "Val Loss: 0.2835, Val Acc: 0.9013, Val F1: 0.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2889: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.2508, Train Acc: 0.8981, Train F1: 0.8829\n",
      "Val Loss: 0.2340, Val Acc: 0.9045, Val F1: 0.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0812: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.1691, Train Acc: 0.9363, Train F1: 0.9296\n",
      "Val Loss: 0.1590, Val Acc: 0.9459, Val F1: 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.1134, Train Acc: 0.9498, Train F1: 0.9447\n",
      "Val Loss: 0.2332, Val Acc: 0.9076, Val F1: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0057: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.0588, Train Acc: 0.9817, Train F1: 0.9810\n",
      "Val Loss: 0.1414, Val Acc: 0.9459, Val F1: 0.9432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.0285, Train Acc: 0.9873, Train F1: 0.9871\n",
      "Val Loss: 0.1545, Val Acc: 0.9522, Val F1: 0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.0322, Train Acc: 0.9881, Train F1: 0.9874\n",
      "Val Loss: 0.2753, Val Acc: 0.9236, Val F1: 0.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0030: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.0268, Train Acc: 0.9920, Train F1: 0.9919\n",
      "Val Loss: 0.1844, Val Acc: 0.9490, Val F1: 0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0182: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0242, Train Acc: 0.9928, Train F1: 0.9930\n",
      "Val Loss: 0.2028, Val Acc: 0.9490, Val F1: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss: 0.0158, Train Acc: 0.9920, Train F1: 0.9915\n",
      "Val Loss: 0.2649, Val Acc: 0.9427, Val F1: 0.9465\n",
      "Early stopping\n",
      "\n",
      "Fine-tuning with misclassified data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0233: 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.0192, Train Acc: 0.9953, Train F1: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0121: 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Train Loss: 0.0242, Train Acc: 0.9953, Train F1: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Train Loss: 0.0079, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0005: 100%|██████████| 7/7 [00:05<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Train Loss: 0.0006, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0017: 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Train Loss: 0.0009, Train Acc: 1.0000, Train F1: 1.0000\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5893: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 1.1355, Train Acc: 0.6425, Train F1: 0.6094\n",
      "Val Loss: 0.3313, Val Acc: 0.8822, Val F1: 0.8322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2319: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.3021, Train Acc: 0.8822, Train F1: 0.8674\n",
      "Val Loss: 0.2439, Val Acc: 0.9108, Val F1: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0319: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.1494, Train Acc: 0.9403, Train F1: 0.9340\n",
      "Val Loss: 0.2276, Val Acc: 0.9236, Val F1: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0891: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.1041, Train Acc: 0.9554, Train F1: 0.9537\n",
      "Val Loss: 0.1598, Val Acc: 0.9331, Val F1: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1453: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.0634, Train Acc: 0.9737, Train F1: 0.9744\n",
      "Val Loss: 0.1860, Val Acc: 0.9427, Val F1: 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0079: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.0479, Train Acc: 0.9817, Train F1: 0.9810\n",
      "Val Loss: 0.2045, Val Acc: 0.9299, Val F1: 0.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0026: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.0210, Train Acc: 0.9920, Train F1: 0.9916\n",
      "Val Loss: 0.5239, Val Acc: 0.9108, Val F1: 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0023: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.0996, Train Acc: 0.9674, Train F1: 0.9665\n",
      "Val Loss: 0.2299, Val Acc: 0.9204, Val F1: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0442: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0272, Train Acc: 0.9912, Train F1: 0.9918\n",
      "Val Loss: 0.2198, Val Acc: 0.9363, Val F1: 0.9295\n",
      "Early stopping\n",
      "\n",
      "Fine-tuning with misclassified data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0025: 100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.0456, Train Acc: 0.9910, Train F1: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0018: 100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Train Loss: 0.0036, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0010: 100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Train Loss: 0.0012, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Train Loss: 0.0027, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 7/7 [00:05<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Train Loss: 0.0003, Train Acc: 1.0000, Train F1: 1.0000\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4951: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.8277, Train Acc: 0.7532, Train F1: 0.7310\n",
      "Val Loss: 0.3096, Val Acc: 0.8949, Val F1: 0.8761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0037: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.2414, Train Acc: 0.9053, Train F1: 0.8950\n",
      "Val Loss: 0.3961, Val Acc: 0.8854, Val F1: 0.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0087: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.1802, Train Acc: 0.9275, Train F1: 0.9228\n",
      "Val Loss: 0.2693, Val Acc: 0.9013, Val F1: 0.8795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0332: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.1195, Train Acc: 0.9459, Train F1: 0.9434\n",
      "Val Loss: 0.2757, Val Acc: 0.9013, Val F1: 0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0636: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.0597, Train Acc: 0.9761, Train F1: 0.9766\n",
      "Val Loss: 0.1685, Val Acc: 0.9363, Val F1: 0.9290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.0498, Train Acc: 0.9777, Train F1: 0.9785\n",
      "Val Loss: 0.2059, Val Acc: 0.9299, Val F1: 0.9291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0080: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.0233, Train Acc: 0.9928, Train F1: 0.9927\n",
      "Val Loss: 0.2588, Val Acc: 0.9331, Val F1: 0.9229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.0178, Train Acc: 0.9944, Train F1: 0.9949\n",
      "Val Loss: 0.3170, Val Acc: 0.9076, Val F1: 0.8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0477: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0291, Train Acc: 0.9920, Train F1: 0.9920\n",
      "Val Loss: 0.1705, Val Acc: 0.9459, Val F1: 0.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0031: 100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss: 0.0265, Train Acc: 0.9881, Train F1: 0.9880\n",
      "Val Loss: 0.2058, Val Acc: 0.9331, Val F1: 0.9272\n",
      "Early stopping\n",
      "\n",
      "Fine-tuning with misclassified data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0030: 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.0170, Train Acc: 0.9962, Train F1: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0005: 100%|██████████| 9/9 [00:06<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Train Loss: 0.0013, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Train Loss: 0.0008, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Train Loss: 0.0005, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Train Loss: 0.0006, Train Acc: 1.0000, Train F1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160351/481695052.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"convNext_model_fold{fold}_final.pth\"))\n",
      "Predicting Fold 1: 100%|██████████| 99/99 [00:18<00:00,  5.29it/s]\n",
      "Predicting Fold 2: 100%|██████████| 99/99 [00:18<00:00,  5.28it/s]\n",
      "Predicting Fold 3: 100%|██████████| 99/99 [00:18<00:00,  5.28it/s]\n",
      "Predicting Fold 4: 100%|██████████| 99/99 [00:18<00:00,  5.28it/s]\n",
      "Predicting Fold 5: 100%|██████████| 99/99 [00:18<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble prediction completed and saved to pred_ensemble.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    misclassified = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_np = preds.argmax(dim=1).detach().cpu().numpy()\n",
    "            targets_np = targets.detach().cpu().numpy()\n",
    "            preds_list.extend(preds_np)\n",
    "            targets_list.extend(targets_np)\n",
    "\n",
    "            misclassified.extend(np.where(preds_np != targets_np)[0])\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1, misclassified\n",
    "\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = 'convnextv2_large'\n",
    "    img_size = 224\n",
    "    LR = 1e-4\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 32\n",
    "    num_workers = 4\n",
    "    n_splits = 5\n",
    "\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        ], p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.5),\n",
    "        ], p=0.5),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(blur_limit=3, p=0.5),\n",
    "            A.MedianBlur(blur_limit=3, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.5),\n",
    "        ], p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=5, border_mode=0, p=0.5),\n",
    "        A.CoarseDropout(max_holes=8, max_height=img_size//20, max_width=img_size//20, min_holes=5, fill_value=255, p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target']), 1):\n",
    "        print(f\"\\nFold {fold}\")\n",
    "\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train/\"), transform=train_transform)\n",
    "        val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train/\"), transform=val_transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "        if fold == 1:\n",
    "            print(f\"\\nModel structure of {model_name}:\")\n",
    "            print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "        best_val_f1 = 0\n",
    "        misclassified_data = []\n",
    "        early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "            val_loss, val_acc, val_f1, misclassified = validate(val_loader, model, loss_fn, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save(model.state_dict(), f\"convNext_model_fold{fold}.pth\")\n",
    "\n",
    "            misclassified_data.extend(val_df.iloc[misclassified].index)\n",
    "\n",
    "            early_stopping(val_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        misclassified_df = df.loc[misclassified_data]\n",
    "        misclassified_dataset = ImageDataset(misclassified_df, os.path.join(data_path, \"train/\"), transform=train_transform)\n",
    "        misclassified_loader = DataLoader(misclassified_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "        print(\"\\nFine-tuning with misclassified data\")\n",
    "        for epoch in range(5):\n",
    "            train_loss, train_acc, train_f1 = train_one_epoch(misclassified_loader, model, optimizer, loss_fn, device)\n",
    "            print(f\"Epoch {epoch+1}/5\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"convNext_model_fold{fold}_final.pth\")\n",
    "\n",
    "    test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test/\"), transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    ensemble_preds = []\n",
    "    for fold in range(1, n_splits + 1):\n",
    "        model.load_state_dict(torch.load(f\"convNext_model_fold{fold}_final.pth\"))\n",
    "        model.eval()\n",
    "        fold_preds = []\n",
    "\n",
    "        for image, _ in tqdm(test_loader, desc=f\"Predicting Fold {fold}\"):\n",
    "            image = image.to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = model(image)\n",
    "            fold_preds.extend(preds.softmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "        ensemble_preds.append(fold_preds)\n",
    "\n",
    "    final_preds = np.mean(ensemble_preds, axis=0).argmax(axis=1)\n",
    "\n",
    "    pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "    pred_df['target'] = final_preds\n",
    "    pred_df.to_csv(\"pred_ensemble.csv\", index=False)\n",
    "    print(\"Ensemble prediction completed and saved to pred_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters Tunning With CNN Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNeXt V2 Large 모델 + Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "# Optuna를 이용한 하이퍼파라미터 최적화 함수\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 설정\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 학습 및 검증\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "\n",
    "    return best_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = '../data/'\n",
    "model_name = 'convnextv2_large'\n",
    "img_size = 224  # ConvNeXt V2에 적합한 이미지 크기\n",
    "EPOCHS = 30\n",
    "num_workers = 4\n",
    "\n",
    "# 데이터 증강 설정\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 데이터 로드 및 분할\n",
    "df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "# Optuna를 이용한 하이퍼파라미터 최적화\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# 최적의 하이퍼파라미터로 최종 모델 학습\n",
    "best_lr = best_params['lr']\n",
    "best_batch_size = best_params['batch_size']\n",
    "best_weight_decay = best_params['weight_decay']\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(f\"\\nModel structure of {model_name}:\")\n",
    "print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "# 학습 루프\n",
    "best_val_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# 테스트 데이터 추론\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "preds_list = []\n",
    "\n",
    "for image, _ in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 저장\n",
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(\"pred.csv\", index=False)\n",
    "print(\"Prediction completed and saved to pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNext V2 Large + WanDB Sweep\n",
    "- pip install wandb\n",
    "- wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "#class ImageDataset(Dataset):\n",
    "\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "#def validate(loader, model, loss_fn, device):\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "#def print_model_summary(model, input_size):\n",
    "\n",
    "\n",
    "# wandb sweep을 위한 학습 함수\n",
    "def train():\n",
    "    # wandb 초기화\n",
    "    run = wandb.init(entity=\"cho\") #사용자에 따라 자신의 도메인 네임 설정!!!\n",
    "    config = wandb.config\n",
    "\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = config.model_name\n",
    "    img_size = config.img_size\n",
    "    LR = config.learning_rate\n",
    "    EPOCHS = config.epochs\n",
    "    BATCH_SIZE = config.batch_size\n",
    "    num_workers = 4\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 모델 설정\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=config.weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    # 모델 구조 출력\n",
    "    print(f\"\\nModel structure of {model_name}:\")\n",
    "    print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "    # 학습 루프\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        # wandb에 로그 기록\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"train_f1\": train_f1,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            wandb.run.summary[\"best_val_f1\"] = best_val_f1\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "# wandb sweep 설정\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_f1',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'model_name': {\n",
    "            'values': ['convnextv2_large', 'efficientnet_b4']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 1e-5,\n",
    "            'max': 1e-3\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [16, 32, 64]\n",
    "        },\n",
    "        'img_size': {\n",
    "            'values': [224, 256, 288]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [1e-5, 1e-4, 1e-3]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 30\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# wandb sweep 실행 및 최고 성능 모델 찾기\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"cvmodel\",entity=\"cho\")\n",
    "wandb.agent(sweep_id, train, count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 최고 성능 모델의 설정 가져오기\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"dl-12/cvmodel/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "best_config = best_run.config\n",
    "\n",
    "  \n",
    "# 최고 성능 모델의 설정 사용\n",
    "model_name = best_config['model_name']\n",
    "img_size = best_config['img_size']\n",
    "BATCH_SIZE = best_config['batch_size']\n",
    "num_workers = 4\n",
    "\n",
    "# 테스트 데이터 변환\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 및 데이터로더 생성\n",
    "test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# 최고 성능 모델 생성\n",
    "model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 테스트 데이터 추론\n",
    "preds_list = []\n",
    "\n",
    "for image, _ in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 저장\n",
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(\"pred.csv\", index=False)\n",
    "print(\"Prediction completed and saved to pred.csv\")\n",
    "\n",
    "# wandb에 결과 업로드\n",
    "wandb.init(project=\"cvmodel\", name=\"best_model_prediction\", entity=\"cho\")\n",
    "wandb.config.update(best_config)\n",
    "wandb.save(\"pred.csv\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 기반 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swin Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2255: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 2.1225, Train Acc: 0.4387, Train F1: 0.4000\n",
      "Val Loss: 0.9821, Val Acc: 0.7452, Val F1: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2761: 100%|██████████| 40/40 [00:20<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "Train Loss: 0.7152, Train Acc: 0.8089, Train F1: 0.7800\n",
      "Val Loss: 0.3570, Val Acc: 0.8758, Val F1: 0.8396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2044: 100%|██████████| 40/40 [00:20<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "Train Loss: 0.3883, Train Acc: 0.8718, Train F1: 0.8491\n",
      "Val Loss: 0.3231, Val Acc: 0.8790, Val F1: 0.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4099: 100%|██████████| 40/40 [00:20<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "Train Loss: 0.2965, Train Acc: 0.8949, Train F1: 0.8821\n",
      "Val Loss: 0.2384, Val Acc: 0.9076, Val F1: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0110: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "Train Loss: 0.2494, Train Acc: 0.9005, Train F1: 0.8933\n",
      "Val Loss: 0.2322, Val Acc: 0.9108, Val F1: 0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2672: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "Train Loss: 0.2011, Train Acc: 0.9291, Train F1: 0.9252\n",
      "Val Loss: 0.2229, Val Acc: 0.9108, Val F1: 0.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1630: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "Train Loss: 0.1676, Train Acc: 0.9403, Train F1: 0.9354\n",
      "Val Loss: 0.2018, Val Acc: 0.9172, Val F1: 0.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1298: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "Train Loss: 0.1479, Train Acc: 0.9451, Train F1: 0.9407\n",
      "Val Loss: 0.2498, Val Acc: 0.9076, Val F1: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1022: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "Train Loss: 0.1438, Train Acc: 0.9475, Train F1: 0.9438\n",
      "Val Loss: 0.1896, Val Acc: 0.9204, Val F1: 0.9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0310: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "Train Loss: 0.1052, Train Acc: 0.9618, Train F1: 0.9584\n",
      "Val Loss: 0.2061, Val Acc: 0.9140, Val F1: 0.9071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0733: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "Train Loss: 0.1105, Train Acc: 0.9562, Train F1: 0.9558\n",
      "Val Loss: 0.2442, Val Acc: 0.9140, Val F1: 0.9016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3388: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "Train Loss: 0.1048, Train Acc: 0.9713, Train F1: 0.9706\n",
      "Val Loss: 0.2352, Val Acc: 0.9204, Val F1: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0013: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "Train Loss: 0.0934, Train Acc: 0.9658, Train F1: 0.9641\n",
      "Val Loss: 0.2637, Val Acc: 0.9076, Val F1: 0.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6437: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "Train Loss: 0.0917, Train Acc: 0.9753, Train F1: 0.9746\n",
      "Val Loss: 0.1850, Val Acc: 0.9236, Val F1: 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0015: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "Train Loss: 0.0817, Train Acc: 0.9761, Train F1: 0.9754\n",
      "Val Loss: 0.1790, Val Acc: 0.9299, Val F1: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0182: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "Train Loss: 0.0501, Train Acc: 0.9825, Train F1: 0.9820\n",
      "Val Loss: 0.2016, Val Acc: 0.9204, Val F1: 0.9149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0443: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "Train Loss: 0.0478, Train Acc: 0.9857, Train F1: 0.9862\n",
      "Val Loss: 0.2867, Val Acc: 0.9140, Val F1: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1051: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "Train Loss: 0.0495, Train Acc: 0.9865, Train F1: 0.9863\n",
      "Val Loss: 0.2206, Val Acc: 0.9236, Val F1: 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0077: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "Train Loss: 0.0449, Train Acc: 0.9833, Train F1: 0.9815\n",
      "Val Loss: 0.3247, Val Acc: 0.9076, Val F1: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0073: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "Train Loss: 0.0382, Train Acc: 0.9881, Train F1: 0.9874\n",
      "Val Loss: 0.3680, Val Acc: 0.8885, Val F1: 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0020: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "Train Loss: 0.0435, Train Acc: 0.9865, Train F1: 0.9868\n",
      "Val Loss: 0.2642, Val Acc: 0.9268, Val F1: 0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0558: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "Train Loss: 0.0300, Train Acc: 0.9912, Train F1: 0.9906\n",
      "Val Loss: 0.2738, Val Acc: 0.9140, Val F1: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0294: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "Train Loss: 0.0204, Train Acc: 0.9968, Train F1: 0.9964\n",
      "Val Loss: 0.2552, Val Acc: 0.9299, Val F1: 0.9243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0047: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "Train Loss: 0.0296, Train Acc: 0.9928, Train F1: 0.9923\n",
      "Val Loss: 0.2686, Val Acc: 0.9299, Val F1: 0.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0081: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "Train Loss: 0.0191, Train Acc: 0.9960, Train F1: 0.9956\n",
      "Val Loss: 0.2523, Val Acc: 0.9268, Val F1: 0.9223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0059: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "Train Loss: 0.0162, Train Acc: 0.9968, Train F1: 0.9970\n",
      "Val Loss: 0.2865, Val Acc: 0.9204, Val F1: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0277: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "Train Loss: 0.0171, Train Acc: 0.9960, Train F1: 0.9956\n",
      "Val Loss: 0.2908, Val Acc: 0.9236, Val F1: 0.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0019: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "Train Loss: 0.0179, Train Acc: 0.9928, Train F1: 0.9930\n",
      "Val Loss: 0.2719, Val Acc: 0.9268, Val F1: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0022: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "Train Loss: 0.0181, Train Acc: 0.9960, Train F1: 0.9963\n",
      "Val Loss: 0.2940, Val Acc: 0.9172, Val F1: 0.9105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0362: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "Train Loss: 0.0182, Train Acc: 0.9976, Train F1: 0.9974\n",
      "Val Loss: 0.2784, Val Acc: 0.9331, Val F1: 0.9268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0245: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "Train Loss: 0.0142, Train Acc: 0.9976, Train F1: 0.9974\n",
      "Val Loss: 0.3143, Val Acc: 0.9172, Val F1: 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0113: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "Train Loss: 0.0207, Train Acc: 0.9952, Train F1: 0.9952\n",
      "Val Loss: 0.2538, Val Acc: 0.9363, Val F1: 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0529: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "Train Loss: 0.0159, Train Acc: 0.9968, Train F1: 0.9971\n",
      "Val Loss: 0.2646, Val Acc: 0.9140, Val F1: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0164: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "Train Loss: 0.0151, Train Acc: 0.9968, Train F1: 0.9967\n",
      "Val Loss: 0.3317, Val Acc: 0.9299, Val F1: 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0020: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "Train Loss: 0.0148, Train Acc: 0.9952, Train F1: 0.9942\n",
      "Val Loss: 0.3107, Val Acc: 0.9236, Val F1: 0.9195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "Train Loss: 0.0147, Train Acc: 0.9960, Train F1: 0.9956\n",
      "Val Loss: 0.3082, Val Acc: 0.9268, Val F1: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "Train Loss: 0.0108, Train Acc: 0.9984, Train F1: 0.9985\n",
      "Val Loss: 0.3278, Val Acc: 0.9172, Val F1: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0077: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "Train Loss: 0.0119, Train Acc: 0.9968, Train F1: 0.9971\n",
      "Val Loss: 0.3541, Val Acc: 0.9268, Val F1: 0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0129: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "Train Loss: 0.0153, Train Acc: 0.9968, Train F1: 0.9971\n",
      "Val Loss: 0.3484, Val Acc: 0.9204, Val F1: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0028: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "Train Loss: 0.0128, Train Acc: 0.9976, Train F1: 0.9978\n",
      "Val Loss: 0.3474, Val Acc: 0.9299, Val F1: 0.9243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0125: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "Train Loss: 0.0056, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3402, Val Acc: 0.9268, Val F1: 0.9203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "Train Loss: 0.0055, Train Acc: 0.9984, Train F1: 0.9985\n",
      "Val Loss: 0.3320, Val Acc: 0.9268, Val F1: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0112: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "Train Loss: 0.0056, Train Acc: 0.9992, Train F1: 0.9989\n",
      "Val Loss: 0.3775, Val Acc: 0.9172, Val F1: 0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0055: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "Train Loss: 0.0103, Train Acc: 0.9984, Train F1: 0.9982\n",
      "Val Loss: 0.3604, Val Acc: 0.9236, Val F1: 0.9195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "Train Loss: 0.0081, Train Acc: 0.9976, Train F1: 0.9978\n",
      "Val Loss: 0.3985, Val Acc: 0.9204, Val F1: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "Train Loss: 0.0197, Train Acc: 0.9936, Train F1: 0.9941\n",
      "Val Loss: 0.3747, Val Acc: 0.9204, Val F1: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "Train Loss: 0.0133, Train Acc: 0.9960, Train F1: 0.9960\n",
      "Val Loss: 0.3457, Val Acc: 0.9363, Val F1: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0089: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "Train Loss: 0.0135, Train Acc: 0.9960, Train F1: 0.9960\n",
      "Val Loss: 0.4326, Val Acc: 0.9076, Val F1: 0.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0010: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "Train Loss: 0.0065, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3269, Val Acc: 0.9331, Val F1: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0017: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "Train Loss: 0.0066, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3312, Val Acc: 0.9331, Val F1: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "Train Loss: 0.0047, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3688, Val Acc: 0.9172, Val F1: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "Train Loss: 0.0104, Train Acc: 0.9976, Train F1: 0.9978\n",
      "Val Loss: 0.3268, Val Acc: 0.9236, Val F1: 0.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0010: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "Train Loss: 0.0066, Train Acc: 0.9984, Train F1: 0.9985\n",
      "Val Loss: 0.3180, Val Acc: 0.9299, Val F1: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0049: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "Train Loss: 0.0031, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3223, Val Acc: 0.9268, Val F1: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "Train Loss: 0.0039, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3420, Val Acc: 0.9268, Val F1: 0.9223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0178: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "Train Loss: 0.0071, Train Acc: 0.9984, Train F1: 0.9985\n",
      "Val Loss: 0.3553, Val Acc: 0.9331, Val F1: 0.9253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "Train Loss: 0.0052, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3424, Val Acc: 0.9299, Val F1: 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "Train Loss: 0.0040, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3258, Val Acc: 0.9299, Val F1: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "Train Loss: 0.0030, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3232, Val Acc: 0.9299, Val F1: 0.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "Train Loss: 0.0033, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3365, Val Acc: 0.9268, Val F1: 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0026: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "Train Loss: 0.0047, Train Acc: 0.9984, Train F1: 0.9982\n",
      "Val Loss: 0.3441, Val Acc: 0.9299, Val F1: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0035: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "Train Loss: 0.0028, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3552, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "Train Loss: 0.0024, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3527, Val Acc: 0.9363, Val F1: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "Train Loss: 0.0028, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3452, Val Acc: 0.9236, Val F1: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0048: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "Train Loss: 0.0044, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3479, Val Acc: 0.9236, Val F1: 0.9174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "Train Loss: 0.0040, Train Acc: 0.9984, Train F1: 0.9982\n",
      "Val Loss: 0.3735, Val Acc: 0.9363, Val F1: 0.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "Train Loss: 0.0025, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3519, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Train Loss: 0.0025, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3649, Val Acc: 0.9395, Val F1: 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "Train Loss: 0.0029, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3491, Val Acc: 0.9331, Val F1: 0.9279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "Train Loss: 0.0041, Train Acc: 0.9984, Train F1: 0.9982\n",
      "Val Loss: 0.3639, Val Acc: 0.9331, Val F1: 0.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "Train Loss: 0.0025, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3557, Val Acc: 0.9363, Val F1: 0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "Train Loss: 0.0021, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3575, Val Acc: 0.9363, Val F1: 0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "Train Loss: 0.0016, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3603, Val Acc: 0.9363, Val F1: 0.9307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0037: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "Train Loss: 0.0023, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3558, Val Acc: 0.9331, Val F1: 0.9275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "Train Loss: 0.0017, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3554, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "Train Loss: 0.0023, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3593, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "Train Loss: 0.0017, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3585, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "Train Loss: 0.0024, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3571, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "Train Loss: 0.0027, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3614, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "Train Loss: 0.0016, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3604, Val Acc: 0.9331, Val F1: 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "Train Loss: 0.0021, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3574, Val Acc: 0.9331, Val F1: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0015: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "Train Loss: 0.0012, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3585, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "Train Loss: 0.0021, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3643, Val Acc: 0.9331, Val F1: 0.9275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "Train Loss: 0.0040, Train Acc: 0.9992, Train F1: 0.9989\n",
      "Val Loss: 0.3703, Val Acc: 0.9299, Val F1: 0.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "Train Loss: 0.0015, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3706, Val Acc: 0.9299, Val F1: 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "Train Loss: 0.0039, Train Acc: 0.9984, Train F1: 0.9982\n",
      "Val Loss: 0.3734, Val Acc: 0.9331, Val F1: 0.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0014: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "Train Loss: 0.0026, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3696, Val Acc: 0.9268, Val F1: 0.9224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "Train Loss: 0.0021, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3685, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "Train Loss: 0.0014, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3691, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "Train Loss: 0.0019, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3700, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "Train Loss: 0.0018, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3707, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "Train Loss: 0.0029, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3704, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "Train Loss: 0.0030, Train Acc: 0.9992, Train F1: 0.9989\n",
      "Val Loss: 0.3707, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "Train Loss: 0.0014, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3710, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "Train Loss: 0.0020, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3709, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "Train Loss: 0.0012, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3708, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0017: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "Train Loss: 0.0014, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3706, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0014: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "Train Loss: 0.0017, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3705, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0011: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "Train Loss: 0.0019, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.3706, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "Train Loss: 0.0013, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.3706, Val Acc: 0.9363, Val F1: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17936/403596892.py:174: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"swin_t_model.pth\"))\n",
      "100%|██████████| 99/99 [00:18<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed and saved to pred_swin.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "# Early Stopping 클래스\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, min_f1_score=0.9):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_f1_score = min_f1_score\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, val_f1):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience and val_f1 >= self.min_f1_score:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            \n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = 'swin_large_patch4_window7_224'  # Swin Transformer Large 모델\n",
    "    img_size = 224  # Swin Transformer에 적합한 이미지 크기\n",
    "    LR = 2e-5  # 1e-4 에서 학습률 조정 : 기존이 더 좋음\n",
    "    EPOCHS = 100 # 30에서 조정 : 기존이 더 좋음\n",
    "    BATCH_SIZE = 32  # 배치 크기 조정\n",
    "    num_workers = 4\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "    test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 모델 설정\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    # Early stopping 설정\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.001, min_f1_score=0.93)\n",
    "\n",
    "    # 모델 구조 출력\n",
    "    # print(f\"\\nModel structure of {model_name}:\")\n",
    "    # print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "    # 학습 루프\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "        val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"swin_t_model.pth\")\n",
    "        \n",
    "        # Early stopping 체크\n",
    "        early_stopping(val_loss, val_f1)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1} with F1 score: {val_f1:.4f}\")\n",
    "            break\n",
    "\n",
    "    # 테스트 데이터 추론\n",
    "    model.load_state_dict(torch.load(\"swin_t_model.pth\"))\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "\n",
    "    for image, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "    # 결과 저장\n",
    "    pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "    pred_df['target'] = preds_list\n",
    "    pred_df.to_csv(\"pred_swin.csv\", index=False)\n",
    "    print(\"Prediction completed and saved to pred_swin.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified k-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1379: 100%|██████████| 40/40 [00:20<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 1.9977, Train Acc: 0.4865, Train F1: 0.4503\n",
      "Val Loss: 0.8827, Val Acc: 0.7739, Val F1: 0.6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4577: 100%|██████████| 40/40 [00:20<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "Train Loss: 0.6732, Train Acc: 0.8049, Train F1: 0.7707\n",
      "Val Loss: 0.4043, Val Acc: 0.8631, Val F1: 0.8179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3563: 100%|██████████| 40/40 [00:20<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "Train Loss: 0.3740, Train Acc: 0.8814, Train F1: 0.8610\n",
      "Val Loss: 0.2678, Val Acc: 0.8822, Val F1: 0.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3622: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "Train Loss: 0.2812, Train Acc: 0.8989, Train F1: 0.8843\n",
      "Val Loss: 0.2281, Val Acc: 0.8949, Val F1: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1351: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "Train Loss: 0.2306, Train Acc: 0.9092, Train F1: 0.8988\n",
      "Val Loss: 0.3207, Val Acc: 0.8885, Val F1: 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4066: 100%|██████████| 40/40 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "Train Loss: 0.1993, Train Acc: 0.9307, Train F1: 0.9236\n",
      "Val Loss: 0.2139, Val Acc: 0.9108, Val F1: 0.8802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0564: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "Train Loss: 0.1616, Train Acc: 0.9411, Train F1: 0.9367\n",
      "Val Loss: 0.2266, Val Acc: 0.9236, Val F1: 0.9109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0156: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "Train Loss: 0.1497, Train Acc: 0.9427, Train F1: 0.9381\n",
      "Val Loss: 0.1785, Val Acc: 0.9076, Val F1: 0.8937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1676: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "Train Loss: 0.1273, Train Acc: 0.9570, Train F1: 0.9535\n",
      "Val Loss: 0.2308, Val Acc: 0.9236, Val F1: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2569: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "Train Loss: 0.1152, Train Acc: 0.9562, Train F1: 0.9555\n",
      "Val Loss: 0.2009, Val Acc: 0.9299, Val F1: 0.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0047: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "Train Loss: 0.0833, Train Acc: 0.9737, Train F1: 0.9735\n",
      "Val Loss: 0.2476, Val Acc: 0.9236, Val F1: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0017: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "Train Loss: 0.1018, Train Acc: 0.9586, Train F1: 0.9557\n",
      "Val Loss: 0.1968, Val Acc: 0.9331, Val F1: 0.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2389: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "Train Loss: 0.1085, Train Acc: 0.9578, Train F1: 0.9558\n",
      "Val Loss: 0.2119, Val Acc: 0.9076, Val F1: 0.8933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0059: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "Train Loss: 0.0823, Train Acc: 0.9705, Train F1: 0.9685\n",
      "Val Loss: 0.1973, Val Acc: 0.9268, Val F1: 0.9177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "Train Loss: 0.0565, Train Acc: 0.9825, Train F1: 0.9822\n",
      "Val Loss: 0.1846, Val Acc: 0.9299, Val F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0499: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "Train Loss: 0.0534, Train Acc: 0.9817, Train F1: 0.9814\n",
      "Val Loss: 0.2300, Val Acc: 0.9268, Val F1: 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0983: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "Train Loss: 0.0583, Train Acc: 0.9833, Train F1: 0.9821\n",
      "Val Loss: 0.1958, Val Acc: 0.9363, Val F1: 0.9308\n",
      "Early stopping triggered at epoch 17 with F1 score: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:18<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7443: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 2.0241, Train Acc: 0.4682, Train F1: 0.4419\n",
      "Val Loss: 0.9525, Val Acc: 0.7516, Val F1: 0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5209: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "Train Loss: 0.7057, Train Acc: 0.7986, Train F1: 0.7692\n",
      "Val Loss: 0.4094, Val Acc: 0.8408, Val F1: 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3512: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "Train Loss: 0.3797, Train Acc: 0.8838, Train F1: 0.8663\n",
      "Val Loss: 0.3192, Val Acc: 0.8631, Val F1: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1091: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "Train Loss: 0.2739, Train Acc: 0.9037, Train F1: 0.8893\n",
      "Val Loss: 0.3723, Val Acc: 0.8694, Val F1: 0.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6342: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "Train Loss: 0.2704, Train Acc: 0.9005, Train F1: 0.8886\n",
      "Val Loss: 0.2797, Val Acc: 0.8854, Val F1: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1422: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "Train Loss: 0.2116, Train Acc: 0.9172, Train F1: 0.9051\n",
      "Val Loss: 0.2317, Val Acc: 0.8949, Val F1: 0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0532: 100%|██████████| 40/40 [00:20<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "Train Loss: 0.1665, Train Acc: 0.9482, Train F1: 0.9401\n",
      "Val Loss: 0.2309, Val Acc: 0.8949, Val F1: 0.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0940: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "Train Loss: 0.1499, Train Acc: 0.9530, Train F1: 0.9486\n",
      "Val Loss: 0.2127, Val Acc: 0.9108, Val F1: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5626: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "Train Loss: 0.1320, Train Acc: 0.9562, Train F1: 0.9528\n",
      "Val Loss: 0.2164, Val Acc: 0.8949, Val F1: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0135: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "Train Loss: 0.1205, Train Acc: 0.9546, Train F1: 0.9499\n",
      "Val Loss: 0.1943, Val Acc: 0.9045, Val F1: 0.8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1353: 100%|██████████| 40/40 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "Train Loss: 0.0913, Train Acc: 0.9745, Train F1: 0.9730\n",
      "Val Loss: 0.2765, Val Acc: 0.9013, Val F1: 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0312:  78%|███████▊  | 31/40 [00:16<00:04,  1.91it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform=None):\n",
    "        self.df = df.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "# Early Stopping 클래스\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, min_f1_score=0.9):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_f1_score = min_f1_score\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, val_f1):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience and val_f1 >= self.min_f1_score:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            \n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    model_name = 'swin_large_patch4_window7_224'  # Swin Transformer Large 모델\n",
    "    img_size = 224  # Swin Transformer에 적합한 이미지 크기\n",
    "    LR = 2e-5  # 1e-4 에서 학습률 조정 : 기존이 더 좋음\n",
    "    EPOCHS = 100 # 30에서 조정 : 기존이 더 좋음\n",
    "    BATCH_SIZE = 32  # 배치 크기 조정\n",
    "    num_workers = 4\n",
    "    n_splits = 5  # Number of K-fold splits\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "\n",
    "    # Stratified K-Fold 설정\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # 전체 결과 저장\n",
    "    final_preds_list = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "\n",
    "        train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "        val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "        test_dataset = ImageDataset(pd.read_csv(os.path.join(data_path, \"sample_submission.csv\")), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "        # 모델 설정\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        # Early stopping 설정\n",
    "        early_stopping = EarlyStopping(patience=5, min_delta=0.001, min_f1_score=0.93)\n",
    "\n",
    "        # 모델 구조 출력\n",
    "        # print(f\"\\nModel structure of {model_name}:\")\n",
    "        # print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "        # 학습 루프\n",
    "        best_val_f1 = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "            val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save(model.state_dict(), f\"swin_t_model_fold_{fold}.pth\")\n",
    "            \n",
    "            # Early stopping 체크\n",
    "            early_stopping(val_loss, val_f1)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1} with F1 score: {val_f1:.4f}\")\n",
    "                break\n",
    "\n",
    "        # 테스트 데이터 추론\n",
    "        model.load_state_dict(torch.load(f\"swin_t_model_fold_{fold}.pth\"))\n",
    "        model.eval()\n",
    "        fold_preds_list = []\n",
    "\n",
    "        for image, _ in tqdm(test_loader):\n",
    "            image = image.to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = model(image)\n",
    "            fold_preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "        # 결과 저장\n",
    "        final_preds_list.append(fold_preds_list)\n",
    "\n",
    "    # 결과 앙상블\n",
    "    final_preds = np.mean(np.array(final_preds_list), axis=0).astype(int)\n",
    "\n",
    "    pred_df = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "    pred_df['target'] = final_preds\n",
    "    pred_df.to_csv(\"pred_swin_kfold.csv\", index=False)\n",
    "    print(\"Prediction completed and saved to pred_swin.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swin-T clustering & classification\n",
    "- 이미지를 유사한 이미지로 5개로 그룹핑 하고 분석하는 모델\n",
    "- early stoping 코드에서 강제적으로 f1 score boundary 를 줄수 있게 변경(분류하면 과소적합이 되는 구간이 있음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Swin-B 모델 로드\n",
    "def load_swin_b_model(num_classes=None):\n",
    "    model = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "# 특성 추출 함수\n",
    "def extract_features(img_path, model):\n",
    "    transform = A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = np.array(img)\n",
    "    img = transform(image=img)['image']\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model.forward_features(img)\n",
    "    return features.squeeze().numpy()\n",
    "\n",
    "# 이미지 클러스터링 함수\n",
    "def cluster_images(data_path, n_clusters=5):\n",
    "    feature_extractor = load_swin_b_model(num_classes=None)\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    image_files = [f for f in os.listdir(data_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    features = []\n",
    "    for img_file in tqdm(image_files, desc=\"Extracting features\"):\n",
    "        img_path = os.path.join(data_path, img_file)\n",
    "        feature = extract_features(img_path, feature_extractor)\n",
    "        features.append(feature.reshape(-1))  # Flatten the feature array\n",
    "    \n",
    "    features = np.array(features)\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    return dict(zip(image_files, clusters))\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, cluster_dict=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.cluster_dict = cluster_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        cluster = self.cluster_dict.get(name, -1) if self.cluster_dict else -1\n",
    "        return img, target, cluster\n",
    "\n",
    "# Early Stopping 클래스\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, min_f1_score=0.9):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_f1_score = min_f1_score\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, val_f1):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience and val_f1 >= self.min_f1_score:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets, _ in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets, _ in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_path = '../data/'\n",
    "    img_size = 224\n",
    "    LR = 2e-5\n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = 32\n",
    "    num_workers = 4\n",
    "    n_clusters = 3\n",
    "\n",
    "    # 클러스터링 수행\n",
    "    print(\"Clustering images...\")\n",
    "    cluster_dict = cluster_images(os.path.join(data_path, \"train_preprocessed/\"), n_clusters)\n",
    "\n",
    "    # 데이터 증강 설정\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    # 데이터 로드 및 분할\n",
    "    df = pd.read_csv(os.path.join(data_path, \"train_correct_labeling.csv\"))\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform, cluster_dict=cluster_dict)\n",
    "    val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform, cluster_dict=cluster_dict)\n",
    "    test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # 각 클러스터에 대한 모델 학습\n",
    "    for cluster in range(n_clusters):\n",
    "        print(f\"\\nTraining model for cluster {cluster}\")\n",
    "        \n",
    "        # 클러스터에 해당하는 데이터만 선택\n",
    "        train_cluster = [data for data in train_dataset if data[2] == cluster]\n",
    "        val_cluster = [data for data in val_dataset if data[2] == cluster]\n",
    "        \n",
    "        if len(train_cluster) == 0 or len(val_cluster) == 0:\n",
    "            print(f\"Skipping cluster {cluster} due to insufficient data\")\n",
    "            continue\n",
    "        \n",
    "        train_cluster_loader = DataLoader(train_cluster, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "        val_cluster_loader = DataLoader(val_cluster, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "        # Swin-B 모델 설정\n",
    "        model = load_swin_b_model(num_classes=17).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "        # Early stopping 설정\n",
    "        early_stopping = EarlyStopping(patience=5, min_delta=0.001, min_f1_score=0.95)\n",
    "\n",
    "\n",
    "        # 모델 구조 출력\n",
    "        # print(f\"\\nModel structure of Swin-B for cluster {cluster}:\")\n",
    "        # print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "        # 학습 루프\n",
    "        best_val_f1 = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc, train_f1 = train_one_epoch(train_cluster_loader, model, optimizer, loss_fn, device)\n",
    "            val_loss, val_acc, val_f1 = validate(val_cluster_loader, model, loss_fn, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save(model.state_dict(), f\"swin_b_model_cluster_{cluster}.pth\")\n",
    "\n",
    "            # Early stopping 체크\n",
    "            early_stopping(val_loss, val_f1)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1} with F1 score: {val_f1:.4f}\")\n",
    "                break\n",
    "\n",
    "    # 테스트 데이터 추론\n",
    "    print(\"\\nPerforming inference on test data\")\n",
    "    test_preds = []\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        model = load_swin_b_model(num_classes=17).to(device)\n",
    "        model.load_state_dict(torch.load(f\"swin_b_model_cluster_{cluster}.pth\"))\n",
    "        model.eval()\n",
    "        \n",
    "        cluster_preds = []\n",
    "        for image, _, _ in tqdm(test_loader, desc=f\"Predicting cluster {cluster}\"):\n",
    "            image = image.to(device)\n",
    "            with torch.no_grad():\n",
    "                preds = model(image)\n",
    "            cluster_preds.extend(preds.detach().cpu().numpy())\n",
    "        \n",
    "        test_preds.append(cluster_preds)\n",
    "    \n",
    "    # 모든 클러스터의 예측을 결합\n",
    "    final_preds = np.mean(test_preds, axis=0)\n",
    "    final_preds = np.argmax(final_preds, axis=1)\n",
    "\n",
    "    # 결과 저장\n",
    "    pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "    pred_df['target'] = final_preds\n",
    "    pred_df.to_csv(\"swin_pred.csv\", index=False)\n",
    "    print(\"Prediction completed and saved to pred.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블\n",
    "CNN 모델(ConvNeXt V2 Large)과 Transformer 모델(ViT Large)을 결합한 앙상블 모델\n",
    "- CNN 모델로 'convnextv2_large'를 사용합니다.\n",
    "- Transformer 모델로 'vit_large_patch16_224'를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convnext v2 + vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found: {img_path}\")\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n",
    "\n",
    "# 앙상블 모델 클래스 정의\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model1, model2):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.model1(x)\n",
    "        out2 = self.model2(x)\n",
    "        return (out1 + out2) / 2\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = '../data/'\n",
    "img_size = 224\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4\n",
    "num_workers = 4\n",
    "\n",
    "# 데이터 증강 설정\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 데이터 로드 및 분할\n",
    "df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "train_dataset = ImageDataset(train_df, os.path.join(data_path, \"train_preprocessed/\"), transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, os.path.join(data_path, \"train_preprocessed/\"), transform=val_transform)\n",
    "test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# 모델 설정\n",
    "model1 = timm.create_model('convnextv2_large', pretrained=True, num_classes=17)\n",
    "model2 = timm.create_model('vit_large_patch16_224', pretrained=True, num_classes=17)\n",
    "\n",
    "ensemble_model = EnsembleModel(model1, model2).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(ensemble_model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# 학습 루프\n",
    "best_val_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(train_loader, ensemble_model, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc, val_f1 = validate(val_loader, ensemble_model, loss_fn, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(ensemble_model.state_dict(), \"best_ensemble_model.pth\")\n",
    "\n",
    "# 테스트 데이터 추론\n",
    "ensemble_model.load_state_dict(torch.load(\"best_ensemble_model.pth\"))\n",
    "ensemble_model.eval()\n",
    "preds_list = []\n",
    "\n",
    "for image, _ in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = ensemble_model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 저장\n",
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(\"ensemble_pred.csv\", index=False)\n",
    "print(\"Prediction completed and saved to ensemble_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 모델 II - 리더 보드 제출용\n",
    "CNN 모델(ConvNeXt V2 Large)과 Transformer 모델(Swin Transformers)을 결합한 앙상블 모델\n",
    "- Hyper Parameter tunning이 전혀 되어 있지 않는 기본 모델 : 향후 최적화 필요\n",
    "- CNN 모델로 'convnextv2_large'를 사용합니다.\n",
    "- Transformer 모델로 'swin_large_patch4_window7_224'를 사용합니다.\n",
    "- software voting(기존 저장된 pth 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 첫 번째 모델과 두 번째 모델 로드\n",
    "model1 = timm.create_model('convnextv2_large', pretrained=False, num_classes=17).to(device)\n",
    "model2 = timm.create_model('swin_large_patch4_window7_224', pretrained=False, num_classes=17).to(device)\n",
    "\n",
    "# 모델 가중치 로드\n",
    "model1.load_state_dict(torch.load('convNext_model.pth'))\n",
    "model2.load_state_dict(torch.load('swin_t_model.pth'))\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_dataset = ImageDataset(os.path.join(data_path, \"sample_submission.csv\"), os.path.join(data_path, \"test_preprocessed/\"), transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# 소프트 보팅을 통한 예측\n",
    "preds_list = []\n",
    "with torch.no_grad():\n",
    "    for image, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        preds1 = model1(image)\n",
    "        preds2 = model2(image)\n",
    "        \n",
    "        # 소프트 보팅: 예측 확률의 평균\n",
    "        preds_avg = (torch.softmax(preds1, dim=1) + torch.softmax(preds2, dim=1)) / 2\n",
    "        preds_list.extend(preds_avg.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# 결과 저장\n",
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(\"ensemble_pred.csv\", index=False)\n",
    "print(\"Ensemble prediction completed and saved to ensemble_pred.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3가지 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

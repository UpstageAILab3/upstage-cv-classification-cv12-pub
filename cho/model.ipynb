{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv.values\n",
    "        else:\n",
    "            self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 정의\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return train_loss, train_acc, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 함수 정의\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in loader:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return val_loss, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = 'datasets_fin/'\n",
    "model_name = 'efficientnet_b0'\n",
    "img_size = 384\n",
    "LR = 1e-3\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 4\n",
    "\n",
    "# 데이터 증강 설정\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 분할\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "train_dataset = ImageDataset(train_df, \"../data/train_preprocessed/\", transform=train_transform)\n",
    "val_dataset = ImageDataset(val_df, \"../data/train_preprocessed/\", transform=val_transform)\n",
    "test_dataset = ImageDataset(\"../data/sample_submission.csv\", \"../data/test_preprocessed/\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model structure of efficientnet_b0:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 192, 192]             864\n",
      "          Identity-2         [-1, 32, 192, 192]               0\n",
      "              SiLU-3         [-1, 32, 192, 192]               0\n",
      "    BatchNormAct2d-4         [-1, 32, 192, 192]              64\n",
      "            Conv2d-5         [-1, 32, 192, 192]             288\n",
      "          Identity-6         [-1, 32, 192, 192]               0\n",
      "              SiLU-7         [-1, 32, 192, 192]               0\n",
      "    BatchNormAct2d-8         [-1, 32, 192, 192]              64\n",
      "            Conv2d-9              [-1, 8, 1, 1]             264\n",
      "             SiLU-10              [-1, 8, 1, 1]               0\n",
      "           Conv2d-11             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-12             [-1, 32, 1, 1]               0\n",
      "    SqueezeExcite-13         [-1, 32, 192, 192]               0\n",
      "           Conv2d-14         [-1, 16, 192, 192]             512\n",
      "         Identity-15         [-1, 16, 192, 192]               0\n",
      "         Identity-16         [-1, 16, 192, 192]               0\n",
      "   BatchNormAct2d-17         [-1, 16, 192, 192]              32\n",
      "DepthwiseSeparableConv-18         [-1, 16, 192, 192]               0\n",
      "           Conv2d-19         [-1, 96, 192, 192]           1,536\n",
      "         Identity-20         [-1, 96, 192, 192]               0\n",
      "             SiLU-21         [-1, 96, 192, 192]               0\n",
      "   BatchNormAct2d-22         [-1, 96, 192, 192]             192\n",
      "           Conv2d-23           [-1, 96, 96, 96]             864\n",
      "         Identity-24           [-1, 96, 96, 96]               0\n",
      "             SiLU-25           [-1, 96, 96, 96]               0\n",
      "   BatchNormAct2d-26           [-1, 96, 96, 96]             192\n",
      "           Conv2d-27              [-1, 4, 1, 1]             388\n",
      "             SiLU-28              [-1, 4, 1, 1]               0\n",
      "           Conv2d-29             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-30             [-1, 96, 1, 1]               0\n",
      "    SqueezeExcite-31           [-1, 96, 96, 96]               0\n",
      "           Conv2d-32           [-1, 24, 96, 96]           2,304\n",
      "         Identity-33           [-1, 24, 96, 96]               0\n",
      "         Identity-34           [-1, 24, 96, 96]               0\n",
      "   BatchNormAct2d-35           [-1, 24, 96, 96]              48\n",
      " InvertedResidual-36           [-1, 24, 96, 96]               0\n",
      "           Conv2d-37          [-1, 144, 96, 96]           3,456\n",
      "         Identity-38          [-1, 144, 96, 96]               0\n",
      "             SiLU-39          [-1, 144, 96, 96]               0\n",
      "   BatchNormAct2d-40          [-1, 144, 96, 96]             288\n",
      "           Conv2d-41          [-1, 144, 96, 96]           1,296\n",
      "         Identity-42          [-1, 144, 96, 96]               0\n",
      "             SiLU-43          [-1, 144, 96, 96]               0\n",
      "   BatchNormAct2d-44          [-1, 144, 96, 96]             288\n",
      "           Conv2d-45              [-1, 6, 1, 1]             870\n",
      "             SiLU-46              [-1, 6, 1, 1]               0\n",
      "           Conv2d-47            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-48            [-1, 144, 1, 1]               0\n",
      "    SqueezeExcite-49          [-1, 144, 96, 96]               0\n",
      "           Conv2d-50           [-1, 24, 96, 96]           3,456\n",
      "         Identity-51           [-1, 24, 96, 96]               0\n",
      "         Identity-52           [-1, 24, 96, 96]               0\n",
      "   BatchNormAct2d-53           [-1, 24, 96, 96]              48\n",
      "         Identity-54           [-1, 24, 96, 96]               0\n",
      " InvertedResidual-55           [-1, 24, 96, 96]               0\n",
      "           Conv2d-56          [-1, 144, 96, 96]           3,456\n",
      "         Identity-57          [-1, 144, 96, 96]               0\n",
      "             SiLU-58          [-1, 144, 96, 96]               0\n",
      "   BatchNormAct2d-59          [-1, 144, 96, 96]             288\n",
      "           Conv2d-60          [-1, 144, 48, 48]           3,600\n",
      "         Identity-61          [-1, 144, 48, 48]               0\n",
      "             SiLU-62          [-1, 144, 48, 48]               0\n",
      "   BatchNormAct2d-63          [-1, 144, 48, 48]             288\n",
      "           Conv2d-64              [-1, 6, 1, 1]             870\n",
      "             SiLU-65              [-1, 6, 1, 1]               0\n",
      "           Conv2d-66            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-67            [-1, 144, 1, 1]               0\n",
      "    SqueezeExcite-68          [-1, 144, 48, 48]               0\n",
      "           Conv2d-69           [-1, 40, 48, 48]           5,760\n",
      "         Identity-70           [-1, 40, 48, 48]               0\n",
      "         Identity-71           [-1, 40, 48, 48]               0\n",
      "   BatchNormAct2d-72           [-1, 40, 48, 48]              80\n",
      " InvertedResidual-73           [-1, 40, 48, 48]               0\n",
      "           Conv2d-74          [-1, 240, 48, 48]           9,600\n",
      "         Identity-75          [-1, 240, 48, 48]               0\n",
      "             SiLU-76          [-1, 240, 48, 48]               0\n",
      "   BatchNormAct2d-77          [-1, 240, 48, 48]             480\n",
      "           Conv2d-78          [-1, 240, 48, 48]           6,000\n",
      "         Identity-79          [-1, 240, 48, 48]               0\n",
      "             SiLU-80          [-1, 240, 48, 48]               0\n",
      "   BatchNormAct2d-81          [-1, 240, 48, 48]             480\n",
      "           Conv2d-82             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-83             [-1, 10, 1, 1]               0\n",
      "           Conv2d-84            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-85            [-1, 240, 1, 1]               0\n",
      "    SqueezeExcite-86          [-1, 240, 48, 48]               0\n",
      "           Conv2d-87           [-1, 40, 48, 48]           9,600\n",
      "         Identity-88           [-1, 40, 48, 48]               0\n",
      "         Identity-89           [-1, 40, 48, 48]               0\n",
      "   BatchNormAct2d-90           [-1, 40, 48, 48]              80\n",
      "         Identity-91           [-1, 40, 48, 48]               0\n",
      " InvertedResidual-92           [-1, 40, 48, 48]               0\n",
      "           Conv2d-93          [-1, 240, 48, 48]           9,600\n",
      "         Identity-94          [-1, 240, 48, 48]               0\n",
      "             SiLU-95          [-1, 240, 48, 48]               0\n",
      "   BatchNormAct2d-96          [-1, 240, 48, 48]             480\n",
      "           Conv2d-97          [-1, 240, 24, 24]           2,160\n",
      "         Identity-98          [-1, 240, 24, 24]               0\n",
      "             SiLU-99          [-1, 240, 24, 24]               0\n",
      "  BatchNormAct2d-100          [-1, 240, 24, 24]             480\n",
      "          Conv2d-101             [-1, 10, 1, 1]           2,410\n",
      "            SiLU-102             [-1, 10, 1, 1]               0\n",
      "          Conv2d-103            [-1, 240, 1, 1]           2,640\n",
      "         Sigmoid-104            [-1, 240, 1, 1]               0\n",
      "   SqueezeExcite-105          [-1, 240, 24, 24]               0\n",
      "          Conv2d-106           [-1, 80, 24, 24]          19,200\n",
      "        Identity-107           [-1, 80, 24, 24]               0\n",
      "        Identity-108           [-1, 80, 24, 24]               0\n",
      "  BatchNormAct2d-109           [-1, 80, 24, 24]             160\n",
      "InvertedResidual-110           [-1, 80, 24, 24]               0\n",
      "          Conv2d-111          [-1, 480, 24, 24]          38,400\n",
      "        Identity-112          [-1, 480, 24, 24]               0\n",
      "            SiLU-113          [-1, 480, 24, 24]               0\n",
      "  BatchNormAct2d-114          [-1, 480, 24, 24]             960\n",
      "          Conv2d-115          [-1, 480, 24, 24]           4,320\n",
      "        Identity-116          [-1, 480, 24, 24]               0\n",
      "            SiLU-117          [-1, 480, 24, 24]               0\n",
      "  BatchNormAct2d-118          [-1, 480, 24, 24]             960\n",
      "          Conv2d-119             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-120             [-1, 20, 1, 1]               0\n",
      "          Conv2d-121            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-122            [-1, 480, 1, 1]               0\n",
      "   SqueezeExcite-123          [-1, 480, 24, 24]               0\n",
      "          Conv2d-124           [-1, 80, 24, 24]          38,400\n",
      "        Identity-125           [-1, 80, 24, 24]               0\n",
      "        Identity-126           [-1, 80, 24, 24]               0\n",
      "  BatchNormAct2d-127           [-1, 80, 24, 24]             160\n",
      "        Identity-128           [-1, 80, 24, 24]               0\n",
      "InvertedResidual-129           [-1, 80, 24, 24]               0\n",
      "          Conv2d-130          [-1, 480, 24, 24]          38,400\n",
      "        Identity-131          [-1, 480, 24, 24]               0\n",
      "            SiLU-132          [-1, 480, 24, 24]               0\n",
      "  BatchNormAct2d-133          [-1, 480, 24, 24]             960\n",
      "          Conv2d-134          [-1, 480, 24, 24]           4,320\n",
      "        Identity-135          [-1, 480, 24, 24]               0\n",
      "            SiLU-136          [-1, 480, 24, 24]               0\n",
      "  BatchNormAct2d-137          [-1, 480, 24, 24]             960\n",
      "          Conv2d-138             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-139             [-1, 20, 1, 1]               0\n",
      "          Conv2d-140            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-141            [-1, 480, 1, 1]               0\n",
      "   SqueezeExcite-142          [-1, 480, 24, 24]               0\n",
      "          Conv2d-143           [-1, 80, 24, 24]          38,400\n",
      "        Identity-144           [-1, 80, 24, 24]               0\n",
      "        Identity-145           [-1, 80, 24, 24]               0\n",
      "  BatchNormAct2d-146           [-1, 80, 24, 24]             160\n",
      "        Identity-147           [-1, 80, 24, 24]               0\n",
      "InvertedResidual-148           [-1, 80, 24, 24]               0\n",
      "          Conv2d-149          [-1, 480, 24, 24]          38,400\n",
      "        Identity-150          [-1, 480, 24, 24]               0\n",
      "            SiLU-151          [-1, 480, 24, 24]               0\n",
      "  BatchNormAct2d-152          [-1, 480, 24, 24]             960\n",
      "          Conv2d-153          [-1, 480, 24, 24]          12,000\n",
      "        Identity-154          [-1, 480, 24, 24]               0\n",
      "            SiLU-155          [-1, 480, 24, 24]               0\n",
      "  BatchNormAct2d-156          [-1, 480, 24, 24]             960\n",
      "          Conv2d-157             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-158             [-1, 20, 1, 1]               0\n",
      "          Conv2d-159            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-160            [-1, 480, 1, 1]               0\n",
      "   SqueezeExcite-161          [-1, 480, 24, 24]               0\n",
      "          Conv2d-162          [-1, 112, 24, 24]          53,760\n",
      "        Identity-163          [-1, 112, 24, 24]               0\n",
      "        Identity-164          [-1, 112, 24, 24]               0\n",
      "  BatchNormAct2d-165          [-1, 112, 24, 24]             224\n",
      "InvertedResidual-166          [-1, 112, 24, 24]               0\n",
      "          Conv2d-167          [-1, 672, 24, 24]          75,264\n",
      "        Identity-168          [-1, 672, 24, 24]               0\n",
      "            SiLU-169          [-1, 672, 24, 24]               0\n",
      "  BatchNormAct2d-170          [-1, 672, 24, 24]           1,344\n",
      "          Conv2d-171          [-1, 672, 24, 24]          16,800\n",
      "        Identity-172          [-1, 672, 24, 24]               0\n",
      "            SiLU-173          [-1, 672, 24, 24]               0\n",
      "  BatchNormAct2d-174          [-1, 672, 24, 24]           1,344\n",
      "          Conv2d-175             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-176             [-1, 28, 1, 1]               0\n",
      "          Conv2d-177            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-178            [-1, 672, 1, 1]               0\n",
      "   SqueezeExcite-179          [-1, 672, 24, 24]               0\n",
      "          Conv2d-180          [-1, 112, 24, 24]          75,264\n",
      "        Identity-181          [-1, 112, 24, 24]               0\n",
      "        Identity-182          [-1, 112, 24, 24]               0\n",
      "  BatchNormAct2d-183          [-1, 112, 24, 24]             224\n",
      "        Identity-184          [-1, 112, 24, 24]               0\n",
      "InvertedResidual-185          [-1, 112, 24, 24]               0\n",
      "          Conv2d-186          [-1, 672, 24, 24]          75,264\n",
      "        Identity-187          [-1, 672, 24, 24]               0\n",
      "            SiLU-188          [-1, 672, 24, 24]               0\n",
      "  BatchNormAct2d-189          [-1, 672, 24, 24]           1,344\n",
      "          Conv2d-190          [-1, 672, 24, 24]          16,800\n",
      "        Identity-191          [-1, 672, 24, 24]               0\n",
      "            SiLU-192          [-1, 672, 24, 24]               0\n",
      "  BatchNormAct2d-193          [-1, 672, 24, 24]           1,344\n",
      "          Conv2d-194             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-195             [-1, 28, 1, 1]               0\n",
      "          Conv2d-196            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-197            [-1, 672, 1, 1]               0\n",
      "   SqueezeExcite-198          [-1, 672, 24, 24]               0\n",
      "          Conv2d-199          [-1, 112, 24, 24]          75,264\n",
      "        Identity-200          [-1, 112, 24, 24]               0\n",
      "        Identity-201          [-1, 112, 24, 24]               0\n",
      "  BatchNormAct2d-202          [-1, 112, 24, 24]             224\n",
      "        Identity-203          [-1, 112, 24, 24]               0\n",
      "InvertedResidual-204          [-1, 112, 24, 24]               0\n",
      "          Conv2d-205          [-1, 672, 24, 24]          75,264\n",
      "        Identity-206          [-1, 672, 24, 24]               0\n",
      "            SiLU-207          [-1, 672, 24, 24]               0\n",
      "  BatchNormAct2d-208          [-1, 672, 24, 24]           1,344\n",
      "          Conv2d-209          [-1, 672, 12, 12]          16,800\n",
      "        Identity-210          [-1, 672, 12, 12]               0\n",
      "            SiLU-211          [-1, 672, 12, 12]               0\n",
      "  BatchNormAct2d-212          [-1, 672, 12, 12]           1,344\n",
      "          Conv2d-213             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-214             [-1, 28, 1, 1]               0\n",
      "          Conv2d-215            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-216            [-1, 672, 1, 1]               0\n",
      "   SqueezeExcite-217          [-1, 672, 12, 12]               0\n",
      "          Conv2d-218          [-1, 192, 12, 12]         129,024\n",
      "        Identity-219          [-1, 192, 12, 12]               0\n",
      "        Identity-220          [-1, 192, 12, 12]               0\n",
      "  BatchNormAct2d-221          [-1, 192, 12, 12]             384\n",
      "InvertedResidual-222          [-1, 192, 12, 12]               0\n",
      "          Conv2d-223         [-1, 1152, 12, 12]         221,184\n",
      "        Identity-224         [-1, 1152, 12, 12]               0\n",
      "            SiLU-225         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-226         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-227         [-1, 1152, 12, 12]          28,800\n",
      "        Identity-228         [-1, 1152, 12, 12]               0\n",
      "            SiLU-229         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-230         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-231             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-232             [-1, 48, 1, 1]               0\n",
      "          Conv2d-233           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-234           [-1, 1152, 1, 1]               0\n",
      "   SqueezeExcite-235         [-1, 1152, 12, 12]               0\n",
      "          Conv2d-236          [-1, 192, 12, 12]         221,184\n",
      "        Identity-237          [-1, 192, 12, 12]               0\n",
      "        Identity-238          [-1, 192, 12, 12]               0\n",
      "  BatchNormAct2d-239          [-1, 192, 12, 12]             384\n",
      "        Identity-240          [-1, 192, 12, 12]               0\n",
      "InvertedResidual-241          [-1, 192, 12, 12]               0\n",
      "          Conv2d-242         [-1, 1152, 12, 12]         221,184\n",
      "        Identity-243         [-1, 1152, 12, 12]               0\n",
      "            SiLU-244         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-245         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-246         [-1, 1152, 12, 12]          28,800\n",
      "        Identity-247         [-1, 1152, 12, 12]               0\n",
      "            SiLU-248         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-249         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-250             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-251             [-1, 48, 1, 1]               0\n",
      "          Conv2d-252           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-253           [-1, 1152, 1, 1]               0\n",
      "   SqueezeExcite-254         [-1, 1152, 12, 12]               0\n",
      "          Conv2d-255          [-1, 192, 12, 12]         221,184\n",
      "        Identity-256          [-1, 192, 12, 12]               0\n",
      "        Identity-257          [-1, 192, 12, 12]               0\n",
      "  BatchNormAct2d-258          [-1, 192, 12, 12]             384\n",
      "        Identity-259          [-1, 192, 12, 12]               0\n",
      "InvertedResidual-260          [-1, 192, 12, 12]               0\n",
      "          Conv2d-261         [-1, 1152, 12, 12]         221,184\n",
      "        Identity-262         [-1, 1152, 12, 12]               0\n",
      "            SiLU-263         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-264         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-265         [-1, 1152, 12, 12]          28,800\n",
      "        Identity-266         [-1, 1152, 12, 12]               0\n",
      "            SiLU-267         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-268         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-269             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-270             [-1, 48, 1, 1]               0\n",
      "          Conv2d-271           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-272           [-1, 1152, 1, 1]               0\n",
      "   SqueezeExcite-273         [-1, 1152, 12, 12]               0\n",
      "          Conv2d-274          [-1, 192, 12, 12]         221,184\n",
      "        Identity-275          [-1, 192, 12, 12]               0\n",
      "        Identity-276          [-1, 192, 12, 12]               0\n",
      "  BatchNormAct2d-277          [-1, 192, 12, 12]             384\n",
      "        Identity-278          [-1, 192, 12, 12]               0\n",
      "InvertedResidual-279          [-1, 192, 12, 12]               0\n",
      "          Conv2d-280         [-1, 1152, 12, 12]         221,184\n",
      "        Identity-281         [-1, 1152, 12, 12]               0\n",
      "            SiLU-282         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-283         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-284         [-1, 1152, 12, 12]          10,368\n",
      "        Identity-285         [-1, 1152, 12, 12]               0\n",
      "            SiLU-286         [-1, 1152, 12, 12]               0\n",
      "  BatchNormAct2d-287         [-1, 1152, 12, 12]           2,304\n",
      "          Conv2d-288             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-289             [-1, 48, 1, 1]               0\n",
      "          Conv2d-290           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-291           [-1, 1152, 1, 1]               0\n",
      "   SqueezeExcite-292         [-1, 1152, 12, 12]               0\n",
      "          Conv2d-293          [-1, 320, 12, 12]         368,640\n",
      "        Identity-294          [-1, 320, 12, 12]               0\n",
      "        Identity-295          [-1, 320, 12, 12]               0\n",
      "  BatchNormAct2d-296          [-1, 320, 12, 12]             640\n",
      "InvertedResidual-297          [-1, 320, 12, 12]               0\n",
      "          Conv2d-298         [-1, 1280, 12, 12]         409,600\n",
      "        Identity-299         [-1, 1280, 12, 12]               0\n",
      "            SiLU-300         [-1, 1280, 12, 12]               0\n",
      "  BatchNormAct2d-301         [-1, 1280, 12, 12]           2,560\n",
      "AdaptiveAvgPool2d-302           [-1, 1280, 1, 1]               0\n",
      "         Flatten-303                 [-1, 1280]               0\n",
      "SelectAdaptivePool2d-304                 [-1, 1280]               0\n",
      "          Linear-305                   [-1, 17]          21,777\n",
      "================================================================\n",
      "Total params: 4,029,325\n",
      "Trainable params: 4,029,325\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 673.87\n",
      "Params size (MB): 15.37\n",
      "Estimated Total Size (MB): 690.93\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Model architecture:\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNormAct2d(\n",
      "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNormAct2d(\n",
      "    1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (classifier): Linear(in_features=1280, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# 모델 구조 출력 함수\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size)\n",
    "    \n",
    "# 모델 구조 출력\n",
    "print(f\"\\nModel structure of {model_name}:\")\n",
    "print_model_summary(model, (3, img_size, img_size))\n",
    "\n",
    "# 모델 아키텍처 출력\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5717: 100%|██████████| 40/40 [00:05<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 0.9814, Train Acc: 0.6998, Train F1: 0.6748\n",
      "Val Loss: 0.6068, Val Acc: 0.8248, Val F1: 0.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2583: 100%|██████████| 40/40 [00:04<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 0.3801, Train Acc: 0.8774, Train F1: 0.8633\n",
      "Val Loss: 0.5170, Val Acc: 0.8599, Val F1: 0.8494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2990: 100%|██████████| 40/40 [00:04<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 0.3013, Train Acc: 0.8854, Train F1: 0.8729\n",
      "Val Loss: 0.3384, Val Acc: 0.8917, Val F1: 0.8819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1913: 100%|██████████| 40/40 [00:04<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 0.2596, Train Acc: 0.9005, Train F1: 0.8936\n",
      "Val Loss: 0.2837, Val Acc: 0.9076, Val F1: 0.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0928: 100%|██████████| 40/40 [00:04<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 0.1830, Train Acc: 0.9299, Train F1: 0.9253\n",
      "Val Loss: 0.3366, Val Acc: 0.8981, Val F1: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2278: 100%|██████████| 40/40 [00:04<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 0.2071, Train Acc: 0.9268, Train F1: 0.9223\n",
      "Val Loss: 0.4114, Val Acc: 0.8885, Val F1: 0.8767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2854: 100%|██████████| 40/40 [00:04<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 0.1562, Train Acc: 0.9530, Train F1: 0.9498\n",
      "Val Loss: 0.3123, Val Acc: 0.9013, Val F1: 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0753: 100%|██████████| 40/40 [00:04<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 0.1782, Train Acc: 0.9411, Train F1: 0.9375\n",
      "Val Loss: 0.2348, Val Acc: 0.9363, Val F1: 0.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0269: 100%|██████████| 40/40 [00:04<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 0.0971, Train Acc: 0.9658, Train F1: 0.9649\n",
      "Val Loss: 0.3019, Val Acc: 0.9013, Val F1: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0446: 100%|██████████| 40/40 [00:04<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss: 0.0920, Train Acc: 0.9682, Train F1: 0.9656\n",
      "Val Loss: 0.2258, Val Acc: 0.9236, Val F1: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0209: 100%|██████████| 40/40 [00:04<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "Train Loss: 0.0641, Train Acc: 0.9801, Train F1: 0.9809\n",
      "Val Loss: 0.2959, Val Acc: 0.9172, Val F1: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0052: 100%|██████████| 40/40 [00:04<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "Train Loss: 0.0577, Train Acc: 0.9809, Train F1: 0.9800\n",
      "Val Loss: 0.2169, Val Acc: 0.9268, Val F1: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0020: 100%|██████████| 40/40 [00:04<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "Train Loss: 0.0424, Train Acc: 0.9857, Train F1: 0.9844\n",
      "Val Loss: 0.2254, Val Acc: 0.9459, Val F1: 0.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0041: 100%|██████████| 40/40 [00:04<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "Train Loss: 0.0198, Train Acc: 0.9928, Train F1: 0.9922\n",
      "Val Loss: 0.2187, Val Acc: 0.9363, Val F1: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|██████████| 40/40 [00:04<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "Train Loss: 0.0213, Train Acc: 0.9936, Train F1: 0.9920\n",
      "Val Loss: 0.2422, Val Acc: 0.9395, Val F1: 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0615: 100%|██████████| 40/40 [00:04<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "Train Loss: 0.0148, Train Acc: 0.9952, Train F1: 0.9956\n",
      "Val Loss: 0.2497, Val Acc: 0.9363, Val F1: 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|██████████| 40/40 [00:04<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "Train Loss: 0.0127, Train Acc: 0.9960, Train F1: 0.9952\n",
      "Val Loss: 0.2342, Val Acc: 0.9522, Val F1: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0056: 100%|██████████| 40/40 [00:04<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "Train Loss: 0.0084, Train Acc: 0.9960, Train F1: 0.9959\n",
      "Val Loss: 0.2615, Val Acc: 0.9363, Val F1: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:04<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "Train Loss: 0.0085, Train Acc: 0.9968, Train F1: 0.9967\n",
      "Val Loss: 0.2679, Val Acc: 0.9395, Val F1: 0.9388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0309: 100%|██████████| 40/40 [00:04<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "Train Loss: 0.0111, Train Acc: 0.9968, Train F1: 0.9967\n",
      "Val Loss: 0.2587, Val Acc: 0.9395, Val F1: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0079: 100%|██████████| 40/40 [00:04<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "Train Loss: 0.0076, Train Acc: 0.9976, Train F1: 0.9974\n",
      "Val Loss: 0.2453, Val Acc: 0.9490, Val F1: 0.9465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0425: 100%|██████████| 40/40 [00:04<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "Train Loss: 0.0051, Train Acc: 0.9984, Train F1: 0.9985\n",
      "Val Loss: 0.2542, Val Acc: 0.9490, Val F1: 0.9468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0113: 100%|██████████| 40/40 [00:04<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "Train Loss: 0.0127, Train Acc: 0.9960, Train F1: 0.9963\n",
      "Val Loss: 0.2502, Val Acc: 0.9459, Val F1: 0.9441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0999: 100%|██████████| 40/40 [00:04<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "Train Loss: 0.0095, Train Acc: 0.9968, Train F1: 0.9964\n",
      "Val Loss: 0.2298, Val Acc: 0.9459, Val F1: 0.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0020: 100%|██████████| 40/40 [00:04<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "Train Loss: 0.0046, Train Acc: 0.9984, Train F1: 0.9982\n",
      "Val Loss: 0.2431, Val Acc: 0.9459, Val F1: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016: 100%|██████████| 40/40 [00:04<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "Train Loss: 0.0056, Train Acc: 0.9976, Train F1: 0.9967\n",
      "Val Loss: 0.2382, Val Acc: 0.9427, Val F1: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2913: 100%|██████████| 40/40 [00:04<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "Train Loss: 0.0131, Train Acc: 0.9976, Train F1: 0.9971\n",
      "Val Loss: 0.2442, Val Acc: 0.9427, Val F1: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:04<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "Train Loss: 0.0028, Train Acc: 0.9984, Train F1: 0.9985\n",
      "Val Loss: 0.2432, Val Acc: 0.9427, Val F1: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0032: 100%|██████████| 40/40 [00:04<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "Train Loss: 0.0035, Train Acc: 0.9992, Train F1: 0.9993\n",
      "Val Loss: 0.2408, Val Acc: 0.9427, Val F1: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|██████████| 40/40 [00:04<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Train Loss: 0.0019, Train Acc: 1.0000, Train F1: 1.0000\n",
      "Val Loss: 0.2418, Val Acc: 0.9427, Val F1: 0.9433\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "best_val_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(train_loader, model, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc, val_f1 = validate(val_loader, model, loss_fn, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 추론\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "preds_list = []\n",
    "\n",
    "for image, _ in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "pred_df.to_csv(\"pred.csv\", index=False)\n",
    "print(\"Prediction completed and saved to pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
